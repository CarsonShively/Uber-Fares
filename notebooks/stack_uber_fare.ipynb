{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stack\n",
        "1. linear regression\n",
        "2. random forrest\n",
        "3. xgboost\n",
        "4. meta model - ridge"
      ],
      "metadata": {
        "id": "XUzwWmU3HS6s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "IsSR1IeOHMww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a4ac28-0c6f-4da6-a6c3-1061ddf66bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.16.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gdown\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.stats import skew\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import shap\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate,  cross_val_score, KFold\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "! pip install -q category_encoders\n",
        "from category_encoders import TargetEncoder\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "! pip install optuna\n",
        "import optuna\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"uber.csv\", quiet=False)\n",
        "df = pd.read_csv(\"uber.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1N4jUZ-jHgc0",
        "outputId": "882336b5-f41b-4e20-fa2e-467512a2b3ce"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\n",
            "To: /content/uber.csv\n",
            "100%|██████████| 23.5M/23.5M [00:00<00:00, 152MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                            key  fare_amount  \\\n",
              "0    24238194    2015-05-07 19:52:06.0000003          7.5   \n",
              "1    27835199    2009-07-17 20:04:56.0000002          7.7   \n",
              "2    44984355   2009-08-24 21:45:00.00000061         12.9   \n",
              "3    25894730    2009-06-26 08:22:21.0000001          5.3   \n",
              "4    17610152  2014-08-28 17:47:00.000000188         16.0   \n",
              "\n",
              "           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
              "0  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
              "1  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
              "2  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
              "3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
              "4  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
              "\n",
              "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
              "0         -73.999512         40.723217                1  \n",
              "1         -73.994710         40.750325                1  \n",
              "2         -73.962565         40.772647                1  \n",
              "3         -73.965316         40.803349                3  \n",
              "4         -73.973082         40.761247                5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3410ea0-7fac-4193-9e80-b3ab1b2a7bd0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24238194</td>\n",
              "      <td>2015-05-07 19:52:06.0000003</td>\n",
              "      <td>7.5</td>\n",
              "      <td>2015-05-07 19:52:06 UTC</td>\n",
              "      <td>-73.999817</td>\n",
              "      <td>40.738354</td>\n",
              "      <td>-73.999512</td>\n",
              "      <td>40.723217</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27835199</td>\n",
              "      <td>2009-07-17 20:04:56.0000002</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2009-07-17 20:04:56 UTC</td>\n",
              "      <td>-73.994355</td>\n",
              "      <td>40.728225</td>\n",
              "      <td>-73.994710</td>\n",
              "      <td>40.750325</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44984355</td>\n",
              "      <td>2009-08-24 21:45:00.00000061</td>\n",
              "      <td>12.9</td>\n",
              "      <td>2009-08-24 21:45:00 UTC</td>\n",
              "      <td>-74.005043</td>\n",
              "      <td>40.740770</td>\n",
              "      <td>-73.962565</td>\n",
              "      <td>40.772647</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25894730</td>\n",
              "      <td>2009-06-26 08:22:21.0000001</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2009-06-26 08:22:21 UTC</td>\n",
              "      <td>-73.976124</td>\n",
              "      <td>40.790844</td>\n",
              "      <td>-73.965316</td>\n",
              "      <td>40.803349</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17610152</td>\n",
              "      <td>2014-08-28 17:47:00.000000188</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2014-08-28 17:47:00 UTC</td>\n",
              "      <td>-73.925023</td>\n",
              "      <td>40.744085</td>\n",
              "      <td>-73.973082</td>\n",
              "      <td>40.761247</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3410ea0-7fac-4193-9e80-b3ab1b2a7bd0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3410ea0-7fac-4193-9e80-b3ab1b2a7bd0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3410ea0-7fac-4193-9e80-b3ab1b2a7bd0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3fe6c892-c016-4d44-82c7-0a5c0dc8afe4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3fe6c892-c016-4d44-82c7-0a5c0dc8afe4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3fe6c892-c016-4d44-82c7-0a5c0dc8afe4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "pGcQi_t6bvU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df['log_fare_amount'] = np.log1p(df['fare_amount'])\n",
        "\n",
        "df = df.dropna(subset=[\n",
        "    'pickup_latitude',\n",
        "    'pickup_longitude',\n",
        "    'dropoff_latitude',\n",
        "    'dropoff_longitude',\n",
        "    'pickup_datetime',\n",
        "    'log_fare_amount'\n",
        "])\n",
        "\n",
        "X = df.drop(columns=['fare_amount', 'log_fare_amount', 'key', 'Unnamed: 0'])\n",
        "y = df['log_fare_amount']\n",
        "\n",
        "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jDaf15hFHiVV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction"
      ],
      "metadata": {
        "id": "nQqF1j4mbxTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, datetime_column='pickup_datetime'):\n",
        "        self.datetime_column = datetime_column\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        X[self.datetime_column] = pd.to_datetime(X[self.datetime_column], errors='coerce')\n",
        "\n",
        "        X['hour'] = X[self.datetime_column].dt.hour\n",
        "        X['weekday'] = X[self.datetime_column].dt.weekday\n",
        "        X['month'] = X[self.datetime_column].dt.month\n",
        "        X['is_weekend'] = X['weekday'] >= 5\n",
        "        X['is_rush_hour'] = X['hour'].isin([7, 8, 9, 16, 17, 18, 19])\n",
        "\n",
        "        X.drop(columns=[self.datetime_column], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CoordinateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_clusters=20):\n",
        "        self.n_clusters = n_clusters\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "        self.kmeans_pickup = None\n",
        "        self.kmeans_dropoff = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        pickup_coords = X[['pickup_latitude', 'pickup_longitude']]\n",
        "        dropoff_coords = X[['dropoff_latitude', 'dropoff_longitude']]\n",
        "\n",
        "        self.kmeans_pickup = KMeans(n_clusters=self.n_clusters, random_state=42).fit(pickup_coords)\n",
        "        self.kmeans_dropoff = KMeans(n_clusters=self.n_clusters, random_state=42).fit(dropoff_coords)\n",
        "\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        def haversine(lat1, lon1, lat2, lon2):\n",
        "            R = 6371\n",
        "            lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "            dlat = lat2 - lat1\n",
        "            dlon = lon2 - lon1\n",
        "            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
        "            return R * 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "        def manhattan(lat1, lon1, lat2, lon2):\n",
        "            return (\n",
        "                haversine(lat1, lon1, lat2, lon1) +\n",
        "                haversine(lat2, lon1, lat2, lon2)\n",
        "            )\n",
        "\n",
        "        def bearing(lat1, lon1, lat2, lon2):\n",
        "            dlon = np.radians(lon2 - lon1)\n",
        "            lat1, lat2 = np.radians(lat1), np.radians(lat2)\n",
        "            x = np.sin(dlon) * np.cos(lat2)\n",
        "            y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(dlon)\n",
        "            return (np.degrees(np.arctan2(x, y)) + 360) % 360\n",
        "\n",
        "        X['distance_km'] = haversine(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['manhattan_km'] = manhattan(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['bearing'] = bearing(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['pickup_cluster'] = self.kmeans_pickup.predict(X[['pickup_latitude', 'pickup_longitude']])\n",
        "        X['dropoff_cluster'] = self.kmeans_dropoff.predict(X[['dropoff_latitude', 'dropoff_longitude']])\n",
        "\n",
        "        X['pickup_grid'] = (\n",
        "            X['pickup_latitude'].round(3).astype(str) + \"_\" +\n",
        "            X['pickup_longitude'].round(3).astype(str)\n",
        "        )\n",
        "\n",
        "        X['dropoff_grid'] = (\n",
        "            X['dropoff_latitude'].round(3).astype(str) + \"_\" +\n",
        "            X['dropoff_longitude'].round(3).astype(str)\n",
        "        )\n",
        "\n",
        "        X.drop(columns=[\n",
        "            'pickup_latitude', 'pickup_longitude',\n",
        "            'dropoff_latitude', 'dropoff_longitude'\n",
        "        ], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y6L8GKHNJy1n"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "UoPwhyoKonZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        X['distance_diff'] = X['manhattan_km'] - X['distance_km']\n",
        "        X['distance_ratio'] = X['manhattan_km'] / X['distance_km']\n",
        "        X['distance_per_passenger'] = X['distance_km'] / X['passenger_count']\n",
        "        X['is_peak_weekend'] = X['is_rush_hour'] * X['is_weekend']\n",
        "        X['total_person_km'] = X['distance_km'] * X['passenger_count']\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "RT53XqJToo8x"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom classes\n",
        "1. to float\n",
        "2. clip range\n",
        "3. cyclic\n",
        "4. target encode wrapper\n",
        "5. inf to nan"
      ],
      "metadata": {
        "id": "0i7TOJQQb0KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToFloat64(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce').astype('float64')\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class ClipToValidRange(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, valid_min=1, valid_max=6):\n",
        "        self.valid_min = valid_min\n",
        "        self.valid_max = valid_max\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            mask = X[col].between(self.valid_min, self.valid_max)\n",
        "            X[col] = X[col].where(mask, np.nan)\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CyclicFeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "        self.hour_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 24),\n",
        "            np.cos(2 * np.pi * X / 24)\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.bearing_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(np.radians(X)),\n",
        "            np.cos(np.radians(X))\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.weekday_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 7),\n",
        "            np.cos(2 * np.pi * X / 7)\n",
        "        ]), validate=False)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        result = pd.DataFrame(index=X.index)\n",
        "\n",
        "        if 'hour' in X.columns:\n",
        "            hour_transformed = self.hour_transformer.transform(X[['hour']])\n",
        "            result[['hour_sin', 'hour_cos']] = pd.DataFrame(hour_transformed, index=X.index)\n",
        "\n",
        "        if 'bearing' in X.columns:\n",
        "            bearing_transformed = self.bearing_transformer.transform(X[['bearing']])\n",
        "            result[['bearing_sin', 'bearing_cos']] = pd.DataFrame(bearing_transformed, index=X.index)\n",
        "\n",
        "        if 'weekday' in X.columns:\n",
        "            weekday_transformed = self.weekday_transformer.transform(X[['weekday']])\n",
        "            result[['weekday_sin', 'weekday_cos']] = pd.DataFrame(weekday_transformed, index=X.index)\n",
        "\n",
        "        if 'hour' in X.columns:\n",
        "            X.drop(columns=['hour'], inplace=True)\n",
        "        if 'bearing' in X.columns:\n",
        "            X.drop(columns=['bearing'], inplace=True)\n",
        "        if 'weekday' in X.columns:\n",
        "            X.drop(columns=['weekday'], inplace=True)\n",
        "\n",
        "        X = pd.concat([X, result], axis=1)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "class TargetEncoderWrapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, cols=None):\n",
        "\n",
        "        self.encoder = ce.TargetEncoder(cols=cols)\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "\n",
        "        self.encoder.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        X_transformed = self.encoder.transform(X)\n",
        "\n",
        "        return pd.DataFrame(X_transformed)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "\n",
        "class InfToNaNTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        X = X.copy()\n",
        "        X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "\n",
        "        return self"
      ],
      "metadata": {
        "id": "IkVS0VkYJ-WD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passenger feature"
      ],
      "metadata": {
        "id": "AcEnKikCb2Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_pipeline = Pipeline([\n",
        "    ('convert_to_float64', ToFloat64()),\n",
        "    ('clip_invalid', ClipToValidRange()),\n",
        "    ('impute_missing', SimpleImputer(strategy='most_frequent'))\n",
        "])"
      ],
      "metadata": {
        "id": "4pwGHlr-KAGS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary features"
      ],
      "metadata": {
        "id": "_ZcyoG75b30P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_pipeline = Pipeline([\n",
        "    ('convert_to_float64', ToFloat64()),\n",
        "    ('impute_missing', SimpleImputer(strategy='most_frequent'))\n",
        "])"
      ],
      "metadata": {
        "id": "NDUm-VIATZGT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distance features"
      ],
      "metadata": {
        "id": "VFBk0QLIb6MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distance_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "])"
      ],
      "metadata": {
        "id": "6fEe9lGZKBxP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cyclic features"
      ],
      "metadata": {
        "id": "1-_RT9T4b70L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cyclic_pipeline = Pipeline([\n",
        "    ('cyclic_features', CyclicFeatureTransformer()),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "dkHafC2qKDlS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One hot features"
      ],
      "metadata": {
        "id": "nCtzoo6fb9sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_pipeline = Pipeline([\n",
        "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])"
      ],
      "metadata": {
        "id": "41SM-S7uKFBW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Target encode features"
      ],
      "metadata": {
        "id": "TU9Y5AIu8MRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_pipeline = Pipeline([\n",
        "    ('target', ce.TargetEncoder())\n",
        "])"
      ],
      "metadata": {
        "id": "CZpDWGRE8N7K"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ratio features"
      ],
      "metadata": {
        "id": "6PmXZTK7-feN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratio_pipeline = Pipeline([\n",
        "    ('inf_to_nan', InfToNaNTransformer()),\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "Or2MElEsvQLm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop low impact features"
      ],
      "metadata": {
        "id": "aj81c-m5cFRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DropLowSHAPFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.features_to_drop = [\n",
        "    \"oh__pickup_cluster_5\", \"oh__dropoff_cluster_4\", \"oh__pickup_cluster_2\", \"oh__pickup_cluster_3\",\n",
        "    \"oh__pickup_cluster_7\", \"oh__pickup_cluster_6\", \"oh__pickup_cluster_4\", \"oh__pickup_cluster_14\",\n",
        "    \"oh__pickup_cluster_15\", \"oh__pickup_cluster_8\", \"oh__pickup_cluster_9\", \"oh__pickup_cluster_10\",\n",
        "    \"oh__dropoff_cluster_3\", \"oh__dropoff_cluster_2\", \"oh__pickup_cluster_17\", \"oh__pickup_cluster_19\",\n",
        "    \"oh__pickup_cluster_12\", \"oh__pickup_cluster_13\", \"oh__dropoff_cluster_6\", \"oh__dropoff_cluster_5\",\n",
        "    \"oh__dropoff_cluster_11\", \"oh__dropoff_cluster_10\", \"oh__dropoff_cluster_8\", \"oh__dropoff_cluster_7\",\n",
        "    \"oh__dropoff_cluster_13\", \"oh__dropoff_cluster_17\", \"oh__dropoff_cluster_18\", \"oh__dropoff_cluster_19\",\n",
        "]\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        drop_cols = [col for col in self.features_to_drop if col in X.columns]\n",
        "        return X.drop(columns=drop_cols)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y3wOVjihoECG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "VKXDgPObcNu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_features = ['passenger_count']\n",
        "binary_features = ['is_weekend', 'is_rush_hour', 'is_peak_weekend']\n",
        "distance_features = ['distance_km', 'manhattan_km', 'distance_diff', 'total_person_km']\n",
        "cyclic_features = ['hour', 'bearing', 'weekday']\n",
        "target_features = ['month', 'pickup_grid', 'dropoff_grid']\n",
        "ratio_features = ['distance_ratio', 'distance_per_passenger']\n",
        "one_hot = ['pickup_cluster', 'dropoff_cluster']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('pass', passenger_pipeline, passenger_features),\n",
        "    ('cyclic', cyclic_pipeline, cyclic_features),\n",
        "    ('tar', target_pipeline, target_features),\n",
        "    ('bin', binary_pipeline, binary_features),\n",
        "    ('dis', distance_pipeline, distance_features),\n",
        "    ('rat', ratio_pipeline, ratio_features),\n",
        "    ('ohe', onehot_pipeline, one_hot),\n",
        "])\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=182,\n",
        "    max_depth=41,\n",
        "    min_samples_split=15,\n",
        "    min_samples_leaf=13,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=149,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.16779455063297968,\n",
        "    min_child_weight=12,\n",
        "    subsample=0.8434805496582364,\n",
        "    colsample_bytree=0.795643706710287,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "base_learners = [\n",
        "    ('lr', LinearRegression()),\n",
        "    ('rf', rf_model),\n",
        "    ('xgb', xgb_model)\n",
        "]\n",
        "\n",
        "meta_model = Ridge(alpha=0.30288462605316574)\n",
        "\n",
        "stacked_model = StackingRegressor(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_model,\n",
        "    passthrough=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('datetime_features', DatetimeFeatureExtractor(datetime_column='pickup_datetime')),\n",
        "    ('coordinate_features', CoordinateFeatureExtractor(n_clusters=20)),\n",
        "    ('feature_engineering', FeatureEngineer()),\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('drop_low_shap', DropLowSHAPFeatures()),\n",
        "    ('model', stacked_model)\n",
        "])\n",
        "\n",
        "full_pipeline.set_output(transform='pandas')\n",
        "\n",
        "_ = full_pipeline"
      ],
      "metadata": {
        "id": "0kZ_58p_Ml0F"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics"
      ],
      "metadata": {
        "id": "-BmfZFZroL-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_subtrain, X_val, y_subtrain, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "full_pipeline.fit(X_subtrain, y_subtrain)\n",
        "y_val_pred_log = full_pipeline.predict(X_val)\n",
        "\n",
        "y_val_true = np.expm1(y_val)\n",
        "y_val_pred = np.expm1(y_val_pred_log)\n",
        "\n",
        "val_rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred))\n",
        "val_mse = mean_squared_error(y_val_true, y_val_pred)\n",
        "val_mae = mean_absolute_error(y_val_true, y_val_pred)\n",
        "val_r2 = r2_score(y_val_true, y_val_pred)\n",
        "\n",
        "print(\"Validation Set Metrics (Un-logged, in dollars):\")\n",
        "print(f\"RMSE: ${val_rmse:.4f}\")\n",
        "print(f\"MSE:  ${val_mse:.4f}\")\n",
        "print(f\"MAE:  ${val_mae:.4f}\")\n",
        "print(f\"R²:   {val_r2:.4f}\")\n",
        "\n",
        "full_pipeline.fit(X_train, y_train)\n",
        "y_holdout_pred_log = full_pipeline.predict(X_holdout)\n",
        "\n",
        "y_holdout_true = np.expm1(y_holdout)\n",
        "y_holdout_pred = np.expm1(y_holdout_pred_log)\n",
        "\n",
        "holdout_rmse = np.sqrt(mean_squared_error(y_holdout_true, y_holdout_pred))\n",
        "holdout_mse = mean_squared_error(y_holdout_true, y_holdout_pred)\n",
        "holdout_mae = mean_absolute_error(y_holdout_true, y_holdout_pred)\n",
        "holdout_r2 = r2_score(y_holdout_true, y_holdout_pred)\n",
        "\n",
        "print(\"\\nHold-Out Set Metrics (Un-logged, in dollars):\")\n",
        "print(f\"RMSE: ${holdout_rmse:.4f}\")\n",
        "print(f\"MSE:  ${holdout_mse:.4f}\")\n",
        "print(f\"MAE:  ${holdout_mae:.4f}\")\n",
        "print(f\"R²:   {holdout_r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFP06gEgZUCo",
        "outputId": "2e4d8d98-5d3e-43fc-b2b8-1457dcd66746"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Metrics (Un-logged, in dollars):\n",
            "RMSE: $4.9521\n",
            "MSE:  $24.5231\n",
            "MAE:  $2.1624\n",
            "R²:   0.7368\n",
            "\n",
            "Hold-Out Set Metrics (Un-logged, in dollars):\n",
            "RMSE: $4.9465\n",
            "MSE:  $24.4677\n",
            "MAE:  $2.1529\n",
            "R²:   0.7426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shap feature analysis"
      ],
      "metadata": {
        "id": "F2-uP8f4oAbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sampled = X_holdout.sample(n=1000, random_state=42)\n",
        "\n",
        "X_sampled_transformed = full_pipeline[:-1].transform(X_sampled)\n",
        "\n",
        "model = full_pipeline.named_steps['model']\n",
        "\n",
        "explainer = shap.Explainer(model.predict, X_sampled_transformed)\n",
        "shap_values = explainer(X_sampled_transformed)\n",
        "\n",
        "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': X_sampled_transformed.columns,\n",
        "    'Mean |SHAP Value|': mean_abs_shap\n",
        "}).sort_values(by='Mean |SHAP Value|', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nSHAP Feature Importances (All Features):\")\n",
        "print(shap_importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hr0pUAR1LC-",
        "outputId": "f7c7d0c5-5a8e-49e5-a2a2-d08560408deb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PermutationExplainer explainer: 1001it [12:19,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SHAP Feature Importances (All Features):\n",
            "                        Feature  Mean |SHAP Value|\n",
            "0              dis__distance_km           0.213521\n",
            "1         ohe__pickup_cluster_0           0.127894\n",
            "2        ohe__pickup_cluster_16           0.103152\n",
            "3             dis__manhattan_km           0.094766\n",
            "4        ohe__pickup_cluster_18           0.069612\n",
            "5        ohe__dropoff_cluster_9           0.043579\n",
            "6        ohe__dropoff_cluster_0           0.042927\n",
            "7             tar__dropoff_grid           0.040236\n",
            "8              cyclic__hour_cos           0.034125\n",
            "9           rat__distance_ratio           0.034084\n",
            "10          cyclic__bearing_sin           0.029416\n",
            "11             tar__pickup_grid           0.024656\n",
            "12         dis__total_person_km           0.021056\n",
            "13             cyclic__hour_sin           0.016639\n",
            "14  rat__distance_per_passenger           0.013662\n",
            "15          cyclic__bearing_cos           0.011680\n",
            "16           dis__distance_diff           0.011322\n",
            "17          cyclic__weekday_cos           0.010632\n",
            "18                   tar__month           0.010516\n",
            "19       ohe__dropoff_cluster_1           0.010095\n",
            "20       ohe__pickup_cluster_11           0.010027\n",
            "21      ohe__dropoff_cluster_16           0.008688\n",
            "22          cyclic__weekday_sin           0.007731\n",
            "23            bin__is_rush_hour           0.004603\n",
            "24         bin__is_peak_weekend           0.004390\n",
            "25      ohe__dropoff_cluster_14           0.004014\n",
            "26        ohe__pickup_cluster_1           0.003094\n",
            "27      ohe__dropoff_cluster_15           0.002510\n",
            "28      ohe__dropoff_cluster_12           0.001893\n",
            "29              bin__is_weekend           0.001584\n",
            "30        pass__passenger_count           0.001361\n",
            "31        ohe__pickup_cluster_5           0.000276\n",
            "32       ohe__dropoff_cluster_4           0.000204\n",
            "33        ohe__pickup_cluster_2           0.000000\n",
            "34        ohe__pickup_cluster_3           0.000000\n",
            "35        ohe__pickup_cluster_7           0.000000\n",
            "36        ohe__pickup_cluster_6           0.000000\n",
            "37        ohe__pickup_cluster_4           0.000000\n",
            "38       ohe__pickup_cluster_14           0.000000\n",
            "39       ohe__pickup_cluster_15           0.000000\n",
            "40        ohe__pickup_cluster_8           0.000000\n",
            "41        ohe__pickup_cluster_9           0.000000\n",
            "42       ohe__pickup_cluster_10           0.000000\n",
            "43       ohe__dropoff_cluster_3           0.000000\n",
            "44       ohe__dropoff_cluster_2           0.000000\n",
            "45       ohe__pickup_cluster_17           0.000000\n",
            "46       ohe__pickup_cluster_19           0.000000\n",
            "47       ohe__pickup_cluster_12           0.000000\n",
            "48       ohe__pickup_cluster_13           0.000000\n",
            "49       ohe__dropoff_cluster_6           0.000000\n",
            "50       ohe__dropoff_cluster_5           0.000000\n",
            "51      ohe__dropoff_cluster_11           0.000000\n",
            "52      ohe__dropoff_cluster_10           0.000000\n",
            "53       ohe__dropoff_cluster_8           0.000000\n",
            "54       ohe__dropoff_cluster_7           0.000000\n",
            "55      ohe__dropoff_cluster_13           0.000000\n",
            "56      ohe__dropoff_cluster_17           0.000000\n",
            "57      ohe__dropoff_cluster_18           0.000000\n",
            "58      ohe__dropoff_cluster_19           0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "The model is generalising well, not overfitting or underfitting, and is accomplishing it's goal well. The top feature is distance followed manhatten distance which makes sense."
      ],
      "metadata": {
        "id": "LZwz3jyiCLB4"
      }
    }
  ]
}