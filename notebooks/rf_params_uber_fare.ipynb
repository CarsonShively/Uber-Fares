{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stack\n",
        "1. linear regression\n",
        "2. random forrest\n",
        "3. xgboost\n",
        "4. meta model - ridge"
      ],
      "metadata": {
        "id": "XUzwWmU3HS6s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "IsSR1IeOHMww"
      },
      "outputs": [],
      "source": [
        "''' !pip install -q gdown '''\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.stats import skew\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import shap\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "''' ! pip install -q category_encoders '''\n",
        "from category_encoders import TargetEncoder\n",
        "''' !pip install category_encoders '''\n",
        "import category_encoders as ce\n",
        "''' ! pip install optuna '''\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"uber.csv\", quiet=False)\n",
        "df = pd.read_csv(\"uber.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1N4jUZ-jHgc0",
        "outputId": "32c9d4eb-89a5-4fd5-a91d-8eaaff3d21e2"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\n",
            "To: /content/uber.csv\n",
            "100%|██████████| 23.5M/23.5M [00:00<00:00, 55.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                            key  fare_amount  \\\n",
              "0    24238194    2015-05-07 19:52:06.0000003          7.5   \n",
              "1    27835199    2009-07-17 20:04:56.0000002          7.7   \n",
              "2    44984355   2009-08-24 21:45:00.00000061         12.9   \n",
              "3    25894730    2009-06-26 08:22:21.0000001          5.3   \n",
              "4    17610152  2014-08-28 17:47:00.000000188         16.0   \n",
              "\n",
              "           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
              "0  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
              "1  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
              "2  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
              "3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
              "4  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
              "\n",
              "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
              "0         -73.999512         40.723217                1  \n",
              "1         -73.994710         40.750325                1  \n",
              "2         -73.962565         40.772647                1  \n",
              "3         -73.965316         40.803349                3  \n",
              "4         -73.973082         40.761247                5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48a71faa-aee1-44f7-81f7-e0b8d2510a6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24238194</td>\n",
              "      <td>2015-05-07 19:52:06.0000003</td>\n",
              "      <td>7.5</td>\n",
              "      <td>2015-05-07 19:52:06 UTC</td>\n",
              "      <td>-73.999817</td>\n",
              "      <td>40.738354</td>\n",
              "      <td>-73.999512</td>\n",
              "      <td>40.723217</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27835199</td>\n",
              "      <td>2009-07-17 20:04:56.0000002</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2009-07-17 20:04:56 UTC</td>\n",
              "      <td>-73.994355</td>\n",
              "      <td>40.728225</td>\n",
              "      <td>-73.994710</td>\n",
              "      <td>40.750325</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44984355</td>\n",
              "      <td>2009-08-24 21:45:00.00000061</td>\n",
              "      <td>12.9</td>\n",
              "      <td>2009-08-24 21:45:00 UTC</td>\n",
              "      <td>-74.005043</td>\n",
              "      <td>40.740770</td>\n",
              "      <td>-73.962565</td>\n",
              "      <td>40.772647</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25894730</td>\n",
              "      <td>2009-06-26 08:22:21.0000001</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2009-06-26 08:22:21 UTC</td>\n",
              "      <td>-73.976124</td>\n",
              "      <td>40.790844</td>\n",
              "      <td>-73.965316</td>\n",
              "      <td>40.803349</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17610152</td>\n",
              "      <td>2014-08-28 17:47:00.000000188</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2014-08-28 17:47:00 UTC</td>\n",
              "      <td>-73.925023</td>\n",
              "      <td>40.744085</td>\n",
              "      <td>-73.973082</td>\n",
              "      <td>40.761247</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48a71faa-aee1-44f7-81f7-e0b8d2510a6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48a71faa-aee1-44f7-81f7-e0b8d2510a6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48a71faa-aee1-44f7-81f7-e0b8d2510a6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f6fd1f9e-c794-4f73-8fd0-94b1bf14ec50\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6fd1f9e-c794-4f73-8fd0-94b1bf14ec50')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f6fd1f9e-c794-4f73-8fd0-94b1bf14ec50 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "pGcQi_t6bvU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df['log_fare_amount'] = np.log1p(df['fare_amount'])\n",
        "\n",
        "df = df.dropna(subset=[\n",
        "    'pickup_latitude',\n",
        "    'pickup_longitude',\n",
        "    'dropoff_latitude',\n",
        "    'dropoff_longitude',\n",
        "    'pickup_datetime',\n",
        "    'log_fare_amount'\n",
        "])\n",
        "\n",
        "X = df.drop(columns=['fare_amount', 'log_fare_amount', 'key', 'Unnamed: 0'])\n",
        "y = df['log_fare_amount']\n",
        "\n",
        "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jDaf15hFHiVV"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction"
      ],
      "metadata": {
        "id": "nQqF1j4mbxTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, datetime_column='pickup_datetime'):\n",
        "        self.datetime_column = datetime_column\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        X[self.datetime_column] = pd.to_datetime(X[self.datetime_column], errors='coerce')\n",
        "\n",
        "        X['hour'] = X[self.datetime_column].dt.hour\n",
        "        X['weekday'] = X[self.datetime_column].dt.weekday\n",
        "        X['month'] = X[self.datetime_column].dt.month\n",
        "        X['is_weekend'] = X['weekday'] >= 5\n",
        "        X['is_rush_hour'] = X['hour'].isin([7, 8, 9, 16, 17, 18, 19])\n",
        "\n",
        "        X.drop(columns=[self.datetime_column], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CoordinateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_clusters=20):\n",
        "        self.n_clusters = n_clusters\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "        self.kmeans_pickup = None\n",
        "        self.kmeans_dropoff = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        pickup_coords = X[['pickup_latitude', 'pickup_longitude']]\n",
        "        dropoff_coords = X[['dropoff_latitude', 'dropoff_longitude']]\n",
        "\n",
        "        self.kmeans_pickup = KMeans(n_clusters=self.n_clusters, random_state=42).fit(pickup_coords)\n",
        "        self.kmeans_dropoff = KMeans(n_clusters=self.n_clusters, random_state=42).fit(dropoff_coords)\n",
        "\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        def haversine(lat1, lon1, lat2, lon2):\n",
        "            R = 6371\n",
        "            lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "            dlat = lat2 - lat1\n",
        "            dlon = lon2 - lon1\n",
        "            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
        "            return R * 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "        def manhattan(lat1, lon1, lat2, lon2):\n",
        "            return (\n",
        "                haversine(lat1, lon1, lat2, lon1) +\n",
        "                haversine(lat2, lon1, lat2, lon2)\n",
        "            )\n",
        "\n",
        "        def bearing(lat1, lon1, lat2, lon2):\n",
        "            dlon = np.radians(lon2 - lon1)\n",
        "            lat1, lat2 = np.radians(lat1), np.radians(lat2)\n",
        "            x = np.sin(dlon) * np.cos(lat2)\n",
        "            y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(dlon)\n",
        "            return (np.degrees(np.arctan2(x, y)) + 360) % 360\n",
        "\n",
        "        X['distance_km'] = haversine(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['manhattan_km'] = manhattan(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['bearing'] = bearing(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['pickup_cluster'] = self.kmeans_pickup.predict(X[['pickup_latitude', 'pickup_longitude']])\n",
        "        X['dropoff_cluster'] = self.kmeans_dropoff.predict(X[['dropoff_latitude', 'dropoff_longitude']])\n",
        "\n",
        "        X['pickup_grid'] = (\n",
        "            X['pickup_latitude'].round(3).astype(str) + \"_\" +\n",
        "            X['pickup_longitude'].round(3).astype(str)\n",
        "        )\n",
        "\n",
        "        X['dropoff_grid'] = (\n",
        "            X['dropoff_latitude'].round(3).astype(str) + \"_\" +\n",
        "            X['dropoff_longitude'].round(3).astype(str)\n",
        "        )\n",
        "\n",
        "        X.drop(columns=[\n",
        "            'pickup_latitude', 'pickup_longitude',\n",
        "            'dropoff_latitude', 'dropoff_longitude'\n",
        "        ], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y6L8GKHNJy1n"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "UoPwhyoKonZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X['distance_diff'] = X['manhattan_km'] - X['distance_km']\n",
        "        X['distance_ratio'] = X['manhattan_km'] / X['distance_km']\n",
        "\n",
        "        X['pickup_lat_long'] = X['pickup_grid'].apply(lambda x: np.array([float(i) for i in x.split('_')]))\n",
        "        X['dropoff_lat_long'] = X['dropoff_grid'].apply(lambda x: np.array([float(i) for i in x.split('_')]))\n",
        "\n",
        "        X['grid_distance'] = [\n",
        "            np.linalg.norm(pickup - dropoff) for pickup, dropoff in zip(X['pickup_lat_long'], X['dropoff_lat_long'])\n",
        "        ]\n",
        "\n",
        "        X['grid_distance_to_manhattan'] = X['grid_distance'] - X['manhattan_km']\n",
        "        X['grid_distance_to_direct'] = X['grid_distance'] - X['distance_km']\n",
        "        X['grid_to_manhattan_ratio'] = X['grid_distance'] / (X['manhattan_km'])\n",
        "        X['grid_to_direct_ratio'] = X['grid_distance'] / (X['distance_km'])\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "RT53XqJToo8x"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom classes\n",
        "1. to float\n",
        "2. clip range\n",
        "3. cyclic\n",
        "4. target encode wrapper\n",
        "5. inf to nan"
      ],
      "metadata": {
        "id": "0i7TOJQQb0KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToFloat64(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce').astype('float64')\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class ClipToValidRange(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, valid_min=1, valid_max=6):\n",
        "        self.valid_min = valid_min\n",
        "        self.valid_max = valid_max\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            mask = X[col].between(self.valid_min, self.valid_max)\n",
        "            X[col] = X[col].where(mask, np.nan)\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CyclicFeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "        self.hour_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 24),\n",
        "            np.cos(2 * np.pi * X / 24)\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.bearing_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(np.radians(X)),\n",
        "            np.cos(np.radians(X))\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.weekday_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 7),\n",
        "            np.cos(2 * np.pi * X / 7)\n",
        "        ]), validate=False)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        result = pd.DataFrame(index=X.index)\n",
        "\n",
        "        if 'hour' in X.columns:\n",
        "            hour_transformed = self.hour_transformer.transform(X[['hour']])\n",
        "            result[['hour_sin', 'hour_cos']] = pd.DataFrame(hour_transformed, index=X.index)\n",
        "\n",
        "        if 'bearing' in X.columns:\n",
        "            bearing_transformed = self.bearing_transformer.transform(X[['bearing']])\n",
        "            result[['bearing_sin', 'bearing_cos']] = pd.DataFrame(bearing_transformed, index=X.index)\n",
        "\n",
        "        if 'weekday' in X.columns:\n",
        "            weekday_transformed = self.weekday_transformer.transform(X[['weekday']])\n",
        "            result[['weekday_sin', 'weekday_cos']] = pd.DataFrame(weekday_transformed, index=X.index)\n",
        "\n",
        "        if 'hour' in X.columns:\n",
        "            X.drop(columns=['hour'], inplace=True)\n",
        "        if 'bearing' in X.columns:\n",
        "            X.drop(columns=['bearing'], inplace=True)\n",
        "        if 'weekday' in X.columns:\n",
        "            X.drop(columns=['weekday'], inplace=True)\n",
        "\n",
        "        X = pd.concat([X, result], axis=1)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "class TargetEncoderWrapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, cols=None):\n",
        "\n",
        "        self.encoder = ce.TargetEncoder(cols=cols)\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "\n",
        "        self.encoder.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        X_transformed = self.encoder.transform(X)\n",
        "\n",
        "        return pd.DataFrame(X_transformed)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "\n",
        "class InfToNaNTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        X = X.copy()\n",
        "        X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "\n",
        "        return self"
      ],
      "metadata": {
        "id": "IkVS0VkYJ-WD"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passenger feature"
      ],
      "metadata": {
        "id": "AcEnKikCb2Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_pipeline = Pipeline([\n",
        "    ('convert_to_float64', ToFloat64()),\n",
        "    ('clip_invalid', ClipToValidRange()),\n",
        "    ('impute_missing', SimpleImputer(strategy='most_frequent'))\n",
        "])"
      ],
      "metadata": {
        "id": "4pwGHlr-KAGS"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary features"
      ],
      "metadata": {
        "id": "_ZcyoG75b30P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_pipeline = Pipeline([\n",
        "    ('convert_to_float64', ToFloat64()),\n",
        "    ('impute_missing', SimpleImputer(strategy='most_frequent'))\n",
        "])"
      ],
      "metadata": {
        "id": "NDUm-VIATZGT"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distance features"
      ],
      "metadata": {
        "id": "VFBk0QLIb6MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distance_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "6fEe9lGZKBxP"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cyclic features"
      ],
      "metadata": {
        "id": "1-_RT9T4b70L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cyclic_pipeline = Pipeline([\n",
        "    ('cyclic_features', CyclicFeatureTransformer()),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "dkHafC2qKDlS"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorical features"
      ],
      "metadata": {
        "id": "nCtzoo6fb9sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_pipeline = Pipeline([\n",
        "    ('cat_clean', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])"
      ],
      "metadata": {
        "id": "41SM-S7uKFBW"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One hot"
      ],
      "metadata": {
        "id": "TU9Y5AIu8MRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_pipeline = Pipeline([\n",
        "    ('target_encoder', ce.TargetEncoder())\n",
        "])"
      ],
      "metadata": {
        "id": "CZpDWGRE8N7K"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ratio features"
      ],
      "metadata": {
        "id": "6PmXZTK7-feN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratio_pipeline = Pipeline([\n",
        "    ('inf_to_nan', InfToNaNTransformer()),\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "Or2MElEsvQLm"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop low impact or highly correlated features"
      ],
      "metadata": {
        "id": "aj81c-m5cFRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DropLowSHAPFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.features_to_drop = [\n",
        "    \"bin_clean__is_rush_hour\", \"oh__pickup_cluster_5\", \"oh__dropoff_cluster_4\",\n",
        "    \"oh__pickup_cluster_17\", \"oh__dropoff_cluster_13\", \"oh__dropoff_cluster_5\",\n",
        "    \"oh__dropoff_cluster_11\", \"oh__pickup_cluster_7\", \"oh__dropoff_cluster_19\",\n",
        "    \"oh__dropoff_cluster_18\", \"oh__pickup_cluster_8\", \"oh__pickup_cluster_6\",\n",
        "    \"oh__dropoff_cluster_8\", \"oh__pickup_cluster_9\", \"oh__pickup_cluster_4\",\n",
        "    \"oh__pickup_cluster_2\", \"oh__pickup_cluster_3\", \"oh__pickup_cluster_12\",\n",
        "    \"oh__pickup_cluster_13\", \"oh__pickup_cluster_14\", \"oh__pickup_cluster_15\",\n",
        "    \"oh__dropoff_cluster_3\", \"oh__dropoff_cluster_2\", \"oh__pickup_cluster_19\",\n",
        "    \"oh__pickup_cluster_10\", \"oh__dropoff_cluster_10\", \"oh__dropoff_cluster_7\",\n",
        "    \"oh__dropoff_cluster_6\", \"oh__dropoff_cluster_17\"\n",
        "]\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        drop_cols = [col for col in self.features_to_drop if col in X.columns]\n",
        "        return X.drop(columns=drop_cols)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y3wOVjihoECG"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "VKXDgPObcNu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "passenger_features = ['passenger_count']\n",
        "\n",
        "binary_features = ['is_weekend', 'is_rush_hour']\n",
        "\n",
        "distance_features = ['distance_km', 'manhattan_km', 'distance_diff', 'grid_distance_to_manhattan', 'grid_distance_to_direct']\n",
        "\n",
        "cyclic_features = ['hour', 'bearing', 'weekday']\n",
        "\n",
        "categorical_features = ['month', 'pickup_grid', 'dropoff_grid']\n",
        "\n",
        "ratio_features = ['distance_diff', 'distance_ratio', 'grid_to_manhattan_ratio', 'grid_to_direct_ratio']\n",
        "\n",
        "one_hot = ['pickup_cluster', 'dropoff_cluster']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('passenger_clean', passenger_pipeline, passenger_features),\n",
        "    ('cyclic_clean', cyclic_pipeline, cyclic_features),\n",
        "    ('cat_clean', categorical_pipeline, categorical_features),\n",
        "    ('bin_clean', binary_pipeline, binary_features),\n",
        "    ('dis_clean', distance_pipeline, distance_features),\n",
        "    ('rat_clean', ratio_pipeline, ratio_features),\n",
        "    ('oh', onehot_pipeline, one_hot),\n",
        "])\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('datetime_features', DatetimeFeatureExtractor(datetime_column='pickup_datetime')),\n",
        "    ('coordinate_features', CoordinateFeatureExtractor(n_clusters=20)),\n",
        "    ('feature_engineering', FeatureEngineer()),\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "])\n",
        "full_pipeline.set_output(transform='pandas')\n",
        "_=full_pipeline"
      ],
      "metadata": {
        "id": "0kZ_58p_Ml0F"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_subtrain, X_val, y_subtrain, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    optuna_pipeline = Pipeline([\n",
        "        ('datetime_features', DatetimeFeatureExtractor(datetime_column='pickup_datetime')),\n",
        "        ('coordinate_features', CoordinateFeatureExtractor(n_clusters=20)),\n",
        "        ('feature_engineering', FeatureEngineer()),\n",
        "        ('preprocessing', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    optuna_pipeline.fit(X_subtrain, y_subtrain)\n",
        "\n",
        "    y_pred = optuna_pipeline.predict(X_val)\n",
        "\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "\n",
        "    return mse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFP06gEgZUCo",
        "outputId": "acfb36f4-6ea5-4157-b261-1897f0ccd6d8"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-31 17:14:55,627] A new study created in memory with name: no-name-87f97218-1e30-4323-8a56-cb982852f00b\n",
            "[I 2025-07-31 17:15:27,650] Trial 0 finished with value: 0.06477979208672635 and parameters: {'n_estimators': 66, 'max_depth': 23, 'min_samples_split': 18, 'min_samples_leaf': 14, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.06477979208672635.\n",
            "[I 2025-07-31 17:16:19,803] Trial 1 finished with value: 0.06527707446888133 and parameters: {'n_estimators': 153, 'max_depth': 23, 'min_samples_split': 19, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.06477979208672635.\n",
            "[I 2025-07-31 17:23:35,852] Trial 2 finished with value: 0.06902773351685669 and parameters: {'n_estimators': 129, 'max_depth': 37, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 0 with value: 0.06477979208672635.\n",
            "[I 2025-07-31 17:24:53,626] Trial 3 finished with value: 0.06426783940979597 and parameters: {'n_estimators': 182, 'max_depth': 41, 'min_samples_split': 15, 'min_samples_leaf': 13, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.06426783940979597.\n",
            "[I 2025-07-31 17:25:23,060] Trial 4 finished with value: 0.0652675535017266 and parameters: {'n_estimators': 75, 'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 3 with value: 0.06426783940979597.\n",
            "[I 2025-07-31 17:26:22,772] Trial 5 finished with value: 0.06544832888885652 and parameters: {'n_estimators': 161, 'max_depth': 13, 'min_samples_split': 19, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.06426783940979597.\n",
            "[I 2025-07-31 17:35:24,743] Trial 6 finished with value: 0.06851932947649644 and parameters: {'n_estimators': 162, 'max_depth': 40, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 3 with value: 0.06426783940979597.\n",
            "[I 2025-07-31 17:39:54,116] Trial 7 finished with value: 0.06772392490332427 and parameters: {'n_estimators': 93, 'max_depth': 29, 'min_samples_split': 14, 'min_samples_leaf': 14, 'max_features': None}. Best is trial 3 with value: 0.06426783940979597.\n",
            "[I 2025-07-31 17:48:18,031] Trial 8 finished with value: 0.06802916315661188 and parameters: {'n_estimators': 165, 'max_depth': 34, 'min_samples_split': 18, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 3 with value: 0.06426783940979597.\n",
            "[I 2025-07-31 17:48:37,186] Trial 9 finished with value: 0.06642941156036425 and parameters: {'n_estimators': 52, 'max_depth': 31, 'min_samples_split': 14, 'min_samples_leaf': 16, 'max_features': 'log2'}. Best is trial 3 with value: 0.06426783940979597.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'n_estimators': 182, 'max_depth': 41, 'min_samples_split': 15, 'min_samples_leaf': 13, 'max_features': 'sqrt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# rf hyperparam tuning\n",
        "1. tuned for mse"
      ],
      "metadata": {
        "id": "qrLkAnqdUX_o"
      }
    }
  ]
}