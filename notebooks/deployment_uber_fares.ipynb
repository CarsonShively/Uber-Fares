{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "5fl7eK66pJYF"
      },
      "outputs": [],
      "source": [
        "!pip install -q gdown category_encoders optuna\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew\n",
        "import gdown\n",
        "import shap\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, KFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
        "from category_encoders import TargetEncoder\n",
        "import category_encoders as ce\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"uber.csv\", quiet=False)\n",
        "df = pd.read_csv(\"uber.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC99qgwHrz21",
        "outputId": "e53e8010-1b36-4e69-a89f-0d572685ff79"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\n",
            "To: /content/uber.csv\n",
            "100%|██████████| 23.5M/23.5M [00:00<00:00, 187MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df['log_fare_amount'] = np.log1p(df['fare_amount'])\n",
        "\n",
        "df = df.dropna(subset=[\n",
        "    'pickup_latitude',\n",
        "    'pickup_longitude',\n",
        "    'dropoff_latitude',\n",
        "    'dropoff_longitude',\n",
        "    'pickup_datetime',\n",
        "    'log_fare_amount'\n",
        "])\n",
        "\n",
        "X = df.drop(columns=['fare_amount', 'log_fare_amount', 'key', 'Unnamed: 0'])\n",
        "y = df['log_fare_amount']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYbaoYHxsQhg",
        "outputId": "8e0e8b90-293b-4b0f-a8c6-8f3cd3ce8f18"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, datetime_column='pickup_datetime'):\n",
        "        self.datetime_column = datetime_column\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        X[self.datetime_column] = pd.to_datetime(X[self.datetime_column], errors='coerce')\n",
        "\n",
        "        X['hour'] = X[self.datetime_column].dt.hour\n",
        "        X['weekday'] = X[self.datetime_column].dt.weekday\n",
        "        X['month'] = X[self.datetime_column].dt.month\n",
        "        X['is_weekend'] = X['weekday'] >= 5\n",
        "        X['is_rush_hour'] = X['hour'].isin([7, 8, 9, 16, 17, 18, 19])\n",
        "\n",
        "        X.drop(columns=[self.datetime_column], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CoordinateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_clusters=20):\n",
        "        self.n_clusters = n_clusters\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "        self.kmeans_pickup = None\n",
        "        self.kmeans_dropoff = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        pickup_coords = X[['pickup_latitude', 'pickup_longitude']]\n",
        "        dropoff_coords = X[['dropoff_latitude', 'dropoff_longitude']]\n",
        "\n",
        "        self.kmeans_pickup = KMeans(n_clusters=self.n_clusters, random_state=42).fit(pickup_coords)\n",
        "        self.kmeans_dropoff = KMeans(n_clusters=self.n_clusters, random_state=42).fit(dropoff_coords)\n",
        "\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        def haversine(lat1, lon1, lat2, lon2):\n",
        "            R = 6371\n",
        "            lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "            dlat = lat2 - lat1\n",
        "            dlon = lon2 - lon1\n",
        "            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
        "            return R * 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "        def manhattan(lat1, lon1, lat2, lon2):\n",
        "            return (\n",
        "                haversine(lat1, lon1, lat2, lon1) +\n",
        "                haversine(lat2, lon1, lat2, lon2)\n",
        "            )\n",
        "\n",
        "        def bearing(lat1, lon1, lat2, lon2):\n",
        "            dlon = np.radians(lon2 - lon1)\n",
        "            lat1, lat2 = np.radians(lat1), np.radians(lat2)\n",
        "            x = np.sin(dlon) * np.cos(lat2)\n",
        "            y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(dlon)\n",
        "            return (np.degrees(np.arctan2(x, y)) + 360) % 360\n",
        "\n",
        "        X['distance_km'] = haversine(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['manhattan_km'] = manhattan(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['bearing'] = bearing(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['pickup_cluster'] = self.kmeans_pickup.predict(X[['pickup_latitude', 'pickup_longitude']])\n",
        "        X['dropoff_cluster'] = self.kmeans_dropoff.predict(X[['dropoff_latitude', 'dropoff_longitude']])\n",
        "\n",
        "        X['pickup_grid'] = (\n",
        "            X['pickup_latitude'].round(3).astype(str) + \"_\" +\n",
        "            X['pickup_longitude'].round(3).astype(str)\n",
        "        )\n",
        "\n",
        "        X['dropoff_grid'] = (\n",
        "            X['dropoff_latitude'].round(3).astype(str) + \"_\" +\n",
        "            X['dropoff_longitude'].round(3).astype(str)\n",
        "        )\n",
        "\n",
        "        X.drop(columns=[\n",
        "            'pickup_latitude', 'pickup_longitude',\n",
        "            'dropoff_latitude', 'dropoff_longitude'\n",
        "        ], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self"
      ],
      "metadata": {
        "id": "QByXc5K4sVZD"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        X['distance_diff'] = X['manhattan_km'] - X['distance_km']\n",
        "        X['distance_ratio'] = X['manhattan_km'] / X['distance_km']\n",
        "        X['distance_per_passenger'] = X['distance_km'] / X['passenger_count']\n",
        "        X['is_peak_weekend'] = X['is_rush_hour'] * X['is_weekend']\n",
        "        X['total_person_km'] = X['distance_km'] * X['passenger_count']\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "VbKiQFbZsXex"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToFloat64(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce').astype('float64')\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class ClipToValidRange(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, valid_min=1, valid_max=6):\n",
        "        self.valid_min = valid_min\n",
        "        self.valid_max = valid_max\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            mask = X[col].between(self.valid_min, self.valid_max)\n",
        "            X[col] = X[col].where(mask, np.nan)\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "def transform_hour(X):\n",
        "    return np.column_stack([\n",
        "        np.sin(2 * np.pi * X / 24),\n",
        "        np.cos(2 * np.pi * X / 24)\n",
        "    ])\n",
        "\n",
        "def transform_bearing(X):\n",
        "    return np.column_stack([\n",
        "        np.sin(np.radians(X)),\n",
        "        np.cos(np.radians(X))\n",
        "    ])\n",
        "\n",
        "def transform_weekday(X):\n",
        "    return np.column_stack([\n",
        "        np.sin(2 * np.pi * X / 7),\n",
        "        np.cos(2 * np.pi * X / 7)\n",
        "    ])\n",
        "\n",
        "class CyclicFeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "        self.hour_transformer = FunctionTransformer(transform_hour, validate=False)\n",
        "        self.bearing_transformer = FunctionTransformer(transform_bearing, validate=False)\n",
        "        self.weekday_transformer = FunctionTransformer(transform_weekday, validate=False)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        result = pd.DataFrame(index=X.index)\n",
        "\n",
        "        if 'hour' in X.columns:\n",
        "            hour_transformed = self.hour_transformer.transform(X[['hour']])\n",
        "            result[['hour_sin', 'hour_cos']] = pd.DataFrame(hour_transformed, index=X.index)\n",
        "\n",
        "        if 'bearing' in X.columns:\n",
        "            bearing_transformed = self.bearing_transformer.transform(X[['bearing']])\n",
        "            result[['bearing_sin', 'bearing_cos']] = pd.DataFrame(bearing_transformed, index=X.index)\n",
        "\n",
        "        if 'weekday' in X.columns:\n",
        "            weekday_transformed = self.weekday_transformer.transform(X[['weekday']])\n",
        "            result[['weekday_sin', 'weekday_cos']] = pd.DataFrame(weekday_transformed, index=X.index)\n",
        "\n",
        "        X.drop(columns=[col for col in ['hour', 'bearing', 'weekday'] if col in X.columns], inplace=True)\n",
        "        X = pd.concat([X, result], axis=1)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "class TargetEncoderWrapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, cols=None):\n",
        "\n",
        "        self.encoder = ce.TargetEncoder(cols=cols)\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "\n",
        "        self.encoder.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        X_transformed = self.encoder.transform(X)\n",
        "\n",
        "        return pd.DataFrame(X_transformed)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "\n",
        "class InfToNaNTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        X = X.copy()\n",
        "        X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "\n",
        "        return self"
      ],
      "metadata": {
        "id": "YGtdrlossa2V"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_pipeline = Pipeline([\n",
        "    ('convert_to_float64', ToFloat64()),\n",
        "    ('clip_invalid', ClipToValidRange()),\n",
        "    ('impute_missing', SimpleImputer(strategy='most_frequent'))\n",
        "])"
      ],
      "metadata": {
        "id": "Rn8YyZJtsdwj"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_pipeline = Pipeline([\n",
        "    ('convert_to_float64', ToFloat64()),\n",
        "    ('impute_missing', SimpleImputer(strategy='most_frequent'))\n",
        "])\n",
        ""
      ],
      "metadata": {
        "id": "fWvgQj29slmm"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "])"
      ],
      "metadata": {
        "id": "n9r7KTX2soKh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cyclic_pipeline = Pipeline([\n",
        "    ('cyclic_features', CyclicFeatureTransformer()),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "_YC3g7LOsrR6"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_pipeline = Pipeline([\n",
        "    ('cat_clean', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])"
      ],
      "metadata": {
        "id": "DnQ30NWcssem"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_pipeline = Pipeline([\n",
        "    ('target_encoder', ce.TargetEncoder())\n",
        "])"
      ],
      "metadata": {
        "id": "5RmMpFOzvat0"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratio_pipeline = Pipeline([\n",
        "    ('inf_to_nan', InfToNaNTransformer()),\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "X9LRJUXrst5Y"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DropLowSHAPFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.features_to_drop = [\n",
        "    \"oh__pickup_cluster_5\", \"oh__dropoff_cluster_4\", \"oh__pickup_cluster_2\", \"oh__pickup_cluster_3\",\n",
        "    \"oh__pickup_cluster_7\", \"oh__pickup_cluster_6\", \"oh__pickup_cluster_4\", \"oh__pickup_cluster_14\",\n",
        "    \"oh__pickup_cluster_15\", \"oh__pickup_cluster_8\", \"oh__pickup_cluster_9\", \"oh__pickup_cluster_10\",\n",
        "    \"oh__dropoff_cluster_3\", \"oh__dropoff_cluster_2\", \"oh__pickup_cluster_17\", \"oh__pickup_cluster_19\",\n",
        "    \"oh__pickup_cluster_12\", \"oh__pickup_cluster_13\", \"oh__dropoff_cluster_6\", \"oh__dropoff_cluster_5\",\n",
        "    \"oh__dropoff_cluster_11\", \"oh__dropoff_cluster_10\", \"oh__dropoff_cluster_8\", \"oh__dropoff_cluster_7\",\n",
        "    \"oh__dropoff_cluster_13\", \"oh__dropoff_cluster_17\", \"oh__dropoff_cluster_18\", \"oh__dropoff_cluster_19\",\n",
        "]\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        drop_cols = [col for col in self.features_to_drop if col in X.columns]\n",
        "        return X.drop(columns=drop_cols)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "u4w_yQZ6tOET"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_features = ['passenger_count']\n",
        "binary_features = ['is_weekend', 'is_rush_hour', 'is_peak_weekend']\n",
        "distance_features = ['distance_km', 'manhattan_km', 'distance_diff', 'total_person_km']\n",
        "cyclic_features = ['hour', 'bearing', 'weekday']\n",
        "target_features = ['month', 'pickup_grid', 'dropoff_grid']\n",
        "ratio_features = ['distance_ratio', 'distance_per_passenger']\n",
        "one_hot = ['pickup_cluster', 'dropoff_cluster']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('pass', passenger_pipeline, passenger_features),\n",
        "    ('cyclic', cyclic_pipeline, cyclic_features),\n",
        "    ('tar', target_pipeline, target_features),\n",
        "    ('bin', binary_pipeline, binary_features),\n",
        "    ('dis', distance_pipeline, distance_features),\n",
        "    ('rat', ratio_pipeline, ratio_features),\n",
        "    ('ohe', onehot_pipeline, one_hot),\n",
        "])\n",
        "\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=182,\n",
        "    max_depth=41,\n",
        "    min_samples_split=15,\n",
        "    min_samples_leaf=13,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=149,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.16779455063297968,\n",
        "    min_child_weight=12,\n",
        "    subsample=0.8434805496582364,\n",
        "    colsample_bytree=0.795643706710287,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "base_learners = [\n",
        "    ('lr', LinearRegression()),\n",
        "    ('rf', rf_model),\n",
        "    ('xgb', xgb_model)\n",
        "]\n",
        "\n",
        "meta_model = Ridge(alpha=0.30288462605316574)\n",
        "\n",
        "stacked_model = StackingRegressor(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_model,\n",
        "    passthrough=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('datetime_features', DatetimeFeatureExtractor(datetime_column='pickup_datetime')),\n",
        "    ('coordinate_features', CoordinateFeatureExtractor(n_clusters=20)),\n",
        "    ('feature_engineering', FeatureEngineer()),\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('drop_low_shap', DropLowSHAPFeatures()),\n",
        "    ('model', stacked_model)\n",
        "])\n",
        "\n",
        "full_pipeline.set_output(transform='pandas')\n",
        "\n",
        "_ = full_pipeline"
      ],
      "metadata": {
        "id": "tLiTx_ZRtQS2"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_pipeline.fit(X, y)\n",
        "\n",
        "joblib.dump(full_pipeline, \"model_pipeline.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsd0R6wAtfnm",
        "outputId": "455f6947-e7d1-4b76-8afa-a54ce3c6ed63"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}