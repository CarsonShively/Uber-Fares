{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stack\n",
        "1. LightGBM\n",
        "3. XGBoost\n",
        "4. meta model - Ridge"
      ],
      "metadata": {
        "id": "XUzwWmU3HS6s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "IsSR1IeOHMww"
      },
      "outputs": [],
      "source": [
        "!pip install -q gdown\n",
        "!pip install -q category_encoders\n",
        "!pip install -q optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import Ridge\n",
        "import shap\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMRegressor\n",
        "import category_encoders as ce\n",
        "from category_encoders import TargetEncoder\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "uhJV8lLz_Bs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"uber.csv\", quiet=False)\n",
        "df = pd.read_csv(\"uber.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1N4jUZ-jHgc0",
        "outputId": "fb24326c-1a71-442d-a8f8-13fc1d4d2c68"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\n",
            "To: /content/uber.csv\n",
            "100%|██████████| 23.5M/23.5M [00:00<00:00, 69.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                            key  fare_amount  \\\n",
              "0    24238194    2015-05-07 19:52:06.0000003          7.5   \n",
              "1    27835199    2009-07-17 20:04:56.0000002          7.7   \n",
              "2    44984355   2009-08-24 21:45:00.00000061         12.9   \n",
              "3    25894730    2009-06-26 08:22:21.0000001          5.3   \n",
              "4    17610152  2014-08-28 17:47:00.000000188         16.0   \n",
              "\n",
              "           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
              "0  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
              "1  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
              "2  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
              "3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
              "4  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
              "\n",
              "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
              "0         -73.999512         40.723217                1  \n",
              "1         -73.994710         40.750325                1  \n",
              "2         -73.962565         40.772647                1  \n",
              "3         -73.965316         40.803349                3  \n",
              "4         -73.973082         40.761247                5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edac7721-2c36-4926-98f6-27b274a93f32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24238194</td>\n",
              "      <td>2015-05-07 19:52:06.0000003</td>\n",
              "      <td>7.5</td>\n",
              "      <td>2015-05-07 19:52:06 UTC</td>\n",
              "      <td>-73.999817</td>\n",
              "      <td>40.738354</td>\n",
              "      <td>-73.999512</td>\n",
              "      <td>40.723217</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27835199</td>\n",
              "      <td>2009-07-17 20:04:56.0000002</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2009-07-17 20:04:56 UTC</td>\n",
              "      <td>-73.994355</td>\n",
              "      <td>40.728225</td>\n",
              "      <td>-73.994710</td>\n",
              "      <td>40.750325</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44984355</td>\n",
              "      <td>2009-08-24 21:45:00.00000061</td>\n",
              "      <td>12.9</td>\n",
              "      <td>2009-08-24 21:45:00 UTC</td>\n",
              "      <td>-74.005043</td>\n",
              "      <td>40.740770</td>\n",
              "      <td>-73.962565</td>\n",
              "      <td>40.772647</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25894730</td>\n",
              "      <td>2009-06-26 08:22:21.0000001</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2009-06-26 08:22:21 UTC</td>\n",
              "      <td>-73.976124</td>\n",
              "      <td>40.790844</td>\n",
              "      <td>-73.965316</td>\n",
              "      <td>40.803349</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17610152</td>\n",
              "      <td>2014-08-28 17:47:00.000000188</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2014-08-28 17:47:00 UTC</td>\n",
              "      <td>-73.925023</td>\n",
              "      <td>40.744085</td>\n",
              "      <td>-73.973082</td>\n",
              "      <td>40.761247</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edac7721-2c36-4926-98f6-27b274a93f32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edac7721-2c36-4926-98f6-27b274a93f32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edac7721-2c36-4926-98f6-27b274a93f32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cd894c74-2f94-47dd-9a0c-e6a22fba72b1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd894c74-2f94-47dd-9a0c-e6a22fba72b1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cd894c74-2f94-47dd-9a0c-e6a22fba72b1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up\n",
        "1. Log transform to habdle skew in the target.\n",
        "2. Drop rows with nans in features without a meaningful imputation value.\n",
        "3. Establish hold out set."
      ],
      "metadata": {
        "id": "pGcQi_t6bvU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df['log_fare_amount'] = np.log1p(df['fare_amount'])\n",
        "\n",
        "df = df.dropna(subset=[\n",
        "    'pickup_latitude',\n",
        "    'pickup_longitude',\n",
        "    'dropoff_latitude',\n",
        "    'dropoff_longitude',\n",
        "    'pickup_datetime',\n",
        "    'log_fare_amount'\n",
        "])\n",
        "\n",
        "X = df.drop(columns=['fare_amount', 'log_fare_amount', 'key', 'Unnamed: 0'])\n",
        "y = df['log_fare_amount']\n",
        "\n",
        "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jDaf15hFHiVV"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction\n",
        "### Datetime features extracted (originals dropped)\n",
        "1. hour\n",
        "2. weekday\n",
        "3. month\n",
        "4. is weekend\n",
        "5. is rush hour\n",
        "6. missing datatime flag\n",
        "\n",
        "If datetime extractor is unable to extract useable datatime, filled with place holder, to prevent crash.\n",
        "\n",
        "### Coordinate features extracted (originals dropped)\n",
        "1. haversine distance\n",
        "2. manhatten distance\n",
        "3. barring\n",
        "4. pickup cluster\n",
        "5. dropoff cluster\n",
        "6. pickup grid\n",
        "7. dropoff grid\n",
        "8. pickup coordinate missing flag\n",
        "9. dropoff coordinate missing flag\n",
        "\n",
        "If coordinate extractor is unable to extract useable coordinates, filled with place holder, to prevent crash."
      ],
      "metadata": {
        "id": "nQqF1j4mbxTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, datetime_column='pickup_datetime', add_missing_flag=True):\n",
        "        self.datetime_column = datetime_column\n",
        "        self.add_missing_flag = add_missing_flag\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "        self.placeholder = pd.Timestamp(\"1900-01-01 00:00:00\")\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        X[self.datetime_column] = pd.to_datetime(X[self.datetime_column], errors='coerce')\n",
        "\n",
        "        if self.add_missing_flag:\n",
        "            X[f'{self.datetime_column}_missing'] = X[self.datetime_column].isna()\n",
        "\n",
        "        X[self.datetime_column] = X[self.datetime_column].fillna(self.placeholder)\n",
        "\n",
        "        X['hour'] = X[self.datetime_column].dt.hour\n",
        "        X['weekday'] = X[self.datetime_column].dt.weekday\n",
        "        X['month'] = X[self.datetime_column].dt.month\n",
        "        X['is_weekend'] = X['weekday'] >= 5\n",
        "        X['is_rush_hour'] = X['hour'].isin([7, 8, 9, 16, 17, 18, 19])\n",
        "\n",
        "        X.drop(columns=[self.datetime_column], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CoordinateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_clusters=20, placeholder=-999.0):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.placeholder = placeholder\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "        self.kmeans_pickup = None\n",
        "        self.kmeans_dropoff = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        pickup_coords = X[['pickup_latitude', 'pickup_longitude']].astype(float)\n",
        "        dropoff_coords = X[['dropoff_latitude', 'dropoff_longitude']].astype(float)\n",
        "\n",
        "        self.kmeans_pickup = KMeans(n_clusters=self.n_clusters, random_state=42).fit(pickup_coords)\n",
        "        self.kmeans_dropoff = KMeans(n_clusters=self.n_clusters, random_state=42).fit(dropoff_coords)\n",
        "\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        for col in ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']:\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "        X['pickup_missing'] = X[['pickup_latitude', 'pickup_longitude']].isna().any(axis=1)\n",
        "        X['dropoff_missing'] = X[['dropoff_latitude', 'dropoff_longitude']].isna().any(axis=1)\n",
        "\n",
        "        for col in ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']:\n",
        "            X[col] = X[col].fillna(self.placeholder)\n",
        "\n",
        "        X['pickup_latitude'] = X['pickup_latitude'].clip(40.5, 41.0)\n",
        "        X['pickup_longitude'] = X['pickup_longitude'].clip(-74.3, -73.6)\n",
        "        X['dropoff_latitude'] = X['dropoff_latitude'].clip(40.5, 41.0)\n",
        "        X['dropoff_longitude'] = X['dropoff_longitude'].clip(-74.3, -73.6)\n",
        "\n",
        "        def haversine(lat1, lon1, lat2, lon2):\n",
        "            R = 6371\n",
        "            lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "            dlat = lat2 - lat1\n",
        "            dlon = lon2 - lon1\n",
        "            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
        "            return R * 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "        def manhattan(lat1, lon1, lat2, lon2):\n",
        "            return (\n",
        "                haversine(lat1, lon1, lat2, lon1) +\n",
        "                haversine(lat2, lon1, lat2, lon2)\n",
        "            )\n",
        "\n",
        "        def bearing(lat1, lon1, lat2, lon2):\n",
        "            dlon = np.radians(lon2 - lon1)\n",
        "            lat1, lat2 = np.radians(lat1), np.radians(lat2)\n",
        "            x = np.sin(dlon) * np.cos(lat2)\n",
        "            y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(dlon)\n",
        "            return (np.degrees(np.arctan2(x, y)) + 360) % 360\n",
        "\n",
        "        X['distance_km'] = haversine(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['manhattan_km'] = manhattan(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['bearing'] = bearing(\n",
        "            X['pickup_latitude'], X['pickup_longitude'],\n",
        "            X['dropoff_latitude'], X['dropoff_longitude']\n",
        "        )\n",
        "\n",
        "        X['pickup_cluster'] = self.kmeans_pickup.predict(X[['pickup_latitude', 'pickup_longitude']])\n",
        "        X['dropoff_cluster'] = self.kmeans_dropoff.predict(X[['dropoff_latitude', 'dropoff_longitude']])\n",
        "\n",
        "        X['pickup_grid'] = (\n",
        "            X['pickup_latitude'].round(3).astype(str) + \"_\" +\n",
        "            X['pickup_longitude'].round(3).astype(str)\n",
        "        )\n",
        "\n",
        "        X['dropoff_grid'] = (\n",
        "            X['dropoff_latitude'].round(3).astype(str) + \"_\" +\n",
        "            X['dropoff_longitude'].round(3).astype(str)\n",
        "        )\n",
        "\n",
        "        X.drop(columns=[\n",
        "            'pickup_latitude', 'pickup_longitude',\n",
        "            'dropoff_latitude', 'dropoff_longitude'\n",
        "        ], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y6L8GKHNJy1n"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "UoPwhyoKonZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        def bin_time(hour):\n",
        "            if 5 <= hour < 12:\n",
        "                return 'morning'\n",
        "            elif 12 <= hour < 17:\n",
        "                return 'afternoon'\n",
        "            elif 17 <= hour < 21:\n",
        "                return 'evening'\n",
        "            else:\n",
        "                return 'night'\n",
        "\n",
        "        X['time_of_day'] = X['hour'].apply(bin_time)\n",
        "        X['is_peak_hour'] = X['hour'].isin([7, 8, 9, 16, 17, 18, 19])\n",
        "\n",
        "        X['pickup_dropoff_same_grid'] = (X['pickup_grid'] == X['dropoff_grid']).astype(int)\n",
        "\n",
        "        X['distance_ratio'] = X['distance_km'] / X['manhattan_km']\n",
        "        X['distance_ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "        X['distance_ratio'].fillna(1.0, inplace=True)\n",
        "\n",
        "        X['cluster_diff'] = np.abs(X['pickup_cluster'] - X['dropoff_cluster'])\n",
        "\n",
        "        X['distance_bearing_sin'] = X['distance_km'] * np.sin(np.radians(X['bearing']))\n",
        "\n",
        "        X['cluster_bearing_offset'] = (\n",
        "            X['dropoff_cluster'] - X['pickup_cluster'] + X['bearing']\n",
        "        )\n",
        "\n",
        "        X['hour_x_is_weekend'] = X['hour'] * X['is_weekend']\n",
        "        X['hour_x_is_rush_hour'] = X['hour'] * X['is_rush_hour']\n",
        "        X['distance_times_cluster_diff'] = X['distance_km'] * X['cluster_diff']\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "RT53XqJToo8x"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom classes\n",
        "1. To float\n",
        "2. Clip to valid range\n",
        "3. Cyclic transforer\n",
        "4. Target encode wrapper"
      ],
      "metadata": {
        "id": "0i7TOJQQb0KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToFloat64(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce').astype('float64')\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class ClipToValidRange(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, valid_min=1, valid_max=6):\n",
        "        self.valid_min = valid_min\n",
        "        self.valid_max = valid_max\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            mask = X[col].between(self.valid_min, self.valid_max)\n",
        "            X[col] = X[col].where(mask, np.nan)\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CyclicFeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "        self.hour_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 24),\n",
        "            np.cos(2 * np.pi * X / 24)\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.bearing_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(np.radians(X)),\n",
        "            np.cos(np.radians(X))\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.weekday_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 7),\n",
        "            np.cos(2 * np.pi * X / 7)\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.month_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 12),\n",
        "            np.cos(2 * np.pi * X / 12)\n",
        "        ]), validate=False)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        result = pd.DataFrame(index=X.index)\n",
        "\n",
        "        if 'hour' in X.columns:\n",
        "            hour_transformed = self.hour_transformer.transform(X[['hour']])\n",
        "            result[['hour_sin', 'hour_cos']] = pd.DataFrame(hour_transformed, index=X.index)\n",
        "\n",
        "        if 'bearing' in X.columns:\n",
        "            bearing_transformed = self.bearing_transformer.transform(X[['bearing']])\n",
        "            result[['bearing_sin', 'bearing_cos']] = pd.DataFrame(bearing_transformed, index=X.index)\n",
        "\n",
        "        if 'weekday' in X.columns:\n",
        "            weekday_transformed = self.weekday_transformer.transform(X[['weekday']])\n",
        "            result[['weekday_sin', 'weekday_cos']] = pd.DataFrame(weekday_transformed, index=X.index)\n",
        "\n",
        "        if 'month' in X.columns:\n",
        "            month_transformed = self.month_transformer.transform(X[['month']])\n",
        "            result[['month_sin', 'month_cos']] = pd.DataFrame(month_transformed, index=X.index)\n",
        "\n",
        "        for col in ['hour', 'bearing', 'weekday', 'month']:\n",
        "            if col in X.columns:\n",
        "                X.drop(columns=[col], inplace=True)\n",
        "\n",
        "        X = pd.concat([X, result], axis=1)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "class TargetEncoderWrapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.encoder = None\n",
        "        self.cols = None\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.cols = X.columns.tolist()\n",
        "        self.encoder = ce.TargetEncoder(cols=self.cols)\n",
        "        self.encoder.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.encoder.transform(X)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class FeatureClipper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, clip_range=(0.0, 99.0)):\n",
        "        self.clip_range = clip_range\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = pd.DataFrame(X)\n",
        "        self.features_ = X.columns.tolist()\n",
        "        self.lower_bounds_ = {}\n",
        "        self.upper_bounds_ = {}\n",
        "\n",
        "        for col in self.features_:\n",
        "            Q1 = X[col].quantile(self.clip_range[0] / 100)\n",
        "            Q3 = X[col].quantile(self.clip_range[1] / 100)\n",
        "            IQR = Q3 - Q1\n",
        "            self.lower_bounds_[col] = Q1 - 1.5 * IQR\n",
        "            self.upper_bounds_[col] = Q3 + 1.5 * IQR\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'features_')\n",
        "        X = pd.DataFrame(X)\n",
        "\n",
        "        for col in self.features_:\n",
        "            X[col] = np.clip(X[col], self.lower_bounds_[col], self.upper_bounds_[col])\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n"
      ],
      "metadata": {
        "id": "IkVS0VkYJ-WD"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passenger feature\n",
        "1. Coerce to float for uniformed nans.\n",
        "2. Clip range to 1-6 people.\n",
        "3. Impute with the mode."
      ],
      "metadata": {
        "id": "AcEnKikCb2Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_pipeline = Pipeline([\n",
        "    ('coerce', ToFloat64()),\n",
        "    ('clip', ClipToValidRange()),\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "])"
      ],
      "metadata": {
        "id": "4pwGHlr-KAGS"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary features\n",
        "1. Coerce to float for numeric binarys, 0 1."
      ],
      "metadata": {
        "id": "_ZcyoG75b30P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_pipeline = Pipeline([\n",
        "    ('coerce', ToFloat64()),\n",
        "])"
      ],
      "metadata": {
        "id": "NDUm-VIATZGT"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cyclic features\n",
        "1. Convert to sinusoidal compenents."
      ],
      "metadata": {
        "id": "1-_RT9T4b70L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cyclic_pipeline = Pipeline([\n",
        "    ('cyclic', CyclicFeatureTransformer()),\n",
        "])"
      ],
      "metadata": {
        "id": "dkHafC2qKDlS"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ordinal features\n",
        "1. Encode the clusters."
      ],
      "metadata": {
        "id": "nCtzoo6fb9sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_pipeline = Pipeline([\n",
        "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "])"
      ],
      "metadata": {
        "id": "41SM-S7uKFBW"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Target encode features\n",
        "1. Encode grids, safe from leakage."
      ],
      "metadata": {
        "id": "TU9Y5AIu8MRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_pipeline = Pipeline([\n",
        "    ('tar', TargetEncoderWrapper())\n",
        "])"
      ],
      "metadata": {
        "id": "CZpDWGRE8N7K"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One hot encode features"
      ],
      "metadata": {
        "id": "Bdkwx1oJPmhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ohe_pipeline = Pipeline([\n",
        "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])"
      ],
      "metadata": {
        "id": "Vk4OpUCyPpnU"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distance features\n",
        "1. Clip extreme values in distance features to avoid skewing features."
      ],
      "metadata": {
        "id": "-2VEw6ZlW9yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distance_pipeline = Pipeline([\n",
        "    ('clip', FeatureClipper())\n",
        "])"
      ],
      "metadata": {
        "id": "yjG1xPK1W_fB"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop low impact features"
      ],
      "metadata": {
        "id": "aj81c-m5cFRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DropFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.features_to_drop = [\n",
        "\n",
        "]\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        drop_cols = [col for col in self.features_to_drop if col in X.columns]\n",
        "        return X.drop(columns=drop_cols)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y3wOVjihoECG"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "VKXDgPObcNu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_features = ['passenger_count']\n",
        "binary_features = ['is_weekend', 'is_rush_hour', 'pickup_missing', 'dropoff_missing', 'pickup_datetime_missing', 'is_peak_hour']\n",
        "cyclic_features = ['hour', 'bearing', 'weekday', 'month']\n",
        "target_features = ['pickup_grid', 'dropoff_grid']\n",
        "ordinal_features = ['pickup_cluster', 'dropoff_cluster']\n",
        "ohe_features = ['time_of_day']\n",
        "distance_features = [\n",
        "    'distance_km',\n",
        "    'manhattan_km',\n",
        "    'distance_ratio',\n",
        "    'cluster_diff',\n",
        "    'distance_bearing_sin',\n",
        "    'cluster_bearing_offset',\n",
        "    'hour_x_is_weekend',\n",
        "    'hour_x_is_rush_hour',\n",
        "    'distance_times_cluster_diff',\n",
        "]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('pass', passenger_pipeline, passenger_features),\n",
        "    ('cyclic', cyclic_pipeline, cyclic_features),\n",
        "    ('tar', target_pipeline, target_features),\n",
        "    ('bin', binary_pipeline, binary_features),\n",
        "    ('ord', ordinal_pipeline, ordinal_features),\n",
        "    ('ohe', ohe_pipeline, ohe_features),\n",
        "    ('dis', distance_pipeline, distance_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "base_learners = [\n",
        "    ('lgbm', LGBMRegressor(random_state=42, n_jobs=-1)),\n",
        "    ('xgb', xgb.XGBRegressor(random_state=42, n_jobs=-1, tree_method='hist'))\n",
        "]\n",
        "\n",
        "meta_model = Ridge(random_state=42)\n",
        "\n",
        "stacked_model = StackingRegressor(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_model,\n",
        "    passthrough=False,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('datetime_features', DatetimeFeatureExtractor(datetime_column='pickup_datetime')),\n",
        "    ('coordinate_features', CoordinateFeatureExtractor(n_clusters=20)),\n",
        "    ('feature_engineering', FeatureEngineer()),\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('model', stacked_model)\n",
        "])\n",
        "\n",
        "full_pipeline.set_output(transform='pandas')\n",
        "\n",
        "_ = full_pipeline"
      ],
      "metadata": {
        "id": "0kZ_58p_Ml0F"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics"
      ],
      "metadata": {
        "id": "-BmfZFZroL-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_subtrain, X_val, y_subtrain, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "full_pipeline.fit(X_subtrain, y_subtrain)\n",
        "y_val_pred_log = full_pipeline.predict(X_val)\n",
        "\n",
        "y_val_true = np.expm1(y_val)\n",
        "y_val_pred = np.expm1(y_val_pred_log)\n",
        "\n",
        "val_rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred))\n",
        "val_mse = mean_squared_error(y_val_true, y_val_pred)\n",
        "val_mae = mean_absolute_error(y_val_true, y_val_pred)\n",
        "val_r2 = r2_score(y_val_true, y_val_pred)\n",
        "\n",
        "print(\"Validation Set Metrics (Un-logged, in dollars):\")\n",
        "print(f\"RMSE: ${val_rmse:.4f}\")\n",
        "print(f\"MSE:  ${val_mse:.4f}\")\n",
        "print(f\"MAE:  ${val_mae:.4f}\")\n",
        "print(f\"R²:   {val_r2:.4f}\")\n",
        "\n",
        "full_pipeline.fit(X_train, y_train)\n",
        "y_holdout_pred_log = full_pipeline.predict(X_holdout)\n",
        "\n",
        "y_holdout_true = np.expm1(y_holdout)\n",
        "y_holdout_pred = np.expm1(y_holdout_pred_log)\n",
        "\n",
        "holdout_rmse = np.sqrt(mean_squared_error(y_holdout_true, y_holdout_pred))\n",
        "holdout_mse = mean_squared_error(y_holdout_true, y_holdout_pred)\n",
        "holdout_mae = mean_absolute_error(y_holdout_true, y_holdout_pred)\n",
        "holdout_r2 = r2_score(y_holdout_true, y_holdout_pred)\n",
        "\n",
        "print(\"\\nHold-Out Set Metrics (Un-logged, in dollars):\")\n",
        "print(f\"RMSE: ${holdout_rmse:.4f}\")\n",
        "print(f\"MSE:  ${holdout_mse:.4f}\")\n",
        "print(f\"MAE:  ${holdout_mae:.4f}\")\n",
        "print(f\"R²:   {holdout_r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFP06gEgZUCo",
        "outputId": "c9ec51ca-4e77-439d-8983-f9a66d21c9d4"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Metrics (Un-logged, in dollars):\n",
            "RMSE: $5.2123\n",
            "MSE:  $27.1681\n",
            "MAE:  $2.2133\n",
            "R²:   0.7084\n",
            "\n",
            "Hold-Out Set Metrics (Un-logged, in dollars):\n",
            "RMSE: $5.2333\n",
            "MSE:  $27.3870\n",
            "MAE:  $2.2063\n",
            "R²:   0.7119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shap feature analysis"
      ],
      "metadata": {
        "id": "F2-uP8f4oAbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sampled = X_holdout.sample(n=1000, random_state=42)\n",
        "\n",
        "X_sampled_transformed = full_pipeline[:-1].transform(X_sampled)\n",
        "\n",
        "model = full_pipeline.named_steps['model']\n",
        "\n",
        "explainer = shap.Explainer(model.predict, X_sampled_transformed)\n",
        "shap_values = explainer(X_sampled_transformed)\n",
        "\n",
        "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': X_sampled_transformed.columns,\n",
        "    'Mean |SHAP Value|': mean_abs_shap\n",
        "}).sort_values(by='Mean |SHAP Value|', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nSHAP Feature Importances (All Features):\")\n",
        "print(shap_importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hr0pUAR1LC-",
        "outputId": "111874f9-dd21-4301-c9ec-6502998624a3"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PermutationExplainer explainer: 1001it [06:35,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SHAP Feature Importances (All Features):\n",
            "                                Feature  Mean |SHAP Value|\n",
            "0                     clip__distance_km           0.327966\n",
            "1                     tar__dropoff_grid           0.063032\n",
            "2                      tar__pickup_grid           0.047075\n",
            "3          clip__cluster_bearing_offset           0.033566\n",
            "4                      cyclic__hour_cos           0.032946\n",
            "5                   cyclic__bearing_sin           0.025823\n",
            "6            clip__distance_bearing_sin           0.021834\n",
            "7                  ord__dropoff_cluster           0.019436\n",
            "8                   cyclic__bearing_cos           0.018480\n",
            "9                  clip__distance_ratio           0.016964\n",
            "10                     cyclic__hour_sin           0.015312\n",
            "11                  ord__pickup_cluster           0.012587\n",
            "12                   clip__manhattan_km           0.010888\n",
            "13                  cyclic__weekday_cos           0.010309\n",
            "14    clip__distance_times_cluster_diff           0.008271\n",
            "15                  cyclic__weekday_sin           0.008004\n",
            "16                   clip__cluster_diff           0.006535\n",
            "17                    cyclic__month_sin           0.006132\n",
            "18                    cyclic__month_cos           0.006043\n",
            "19                pass__passenger_count           0.004866\n",
            "20              clip__hour_x_is_weekend           0.004158\n",
            "21               ohe__time_of_day_night           0.003331\n",
            "22            clip__hour_x_is_rush_hour           0.001871\n",
            "23  remainder__pickup_dropoff_same_grid           0.001793\n",
            "24                    bin__is_rush_hour           0.000386\n",
            "25             ohe__time_of_day_morning           0.000252\n",
            "26           ohe__time_of_day_afternoon           0.000232\n",
            "27             ohe__time_of_day_evening           0.000186\n",
            "28                    bin__is_peak_hour           0.000007\n",
            "29                      bin__is_weekend           0.000005\n",
            "30         bin__pickup_datetime_missing           0.000000\n",
            "31                  bin__pickup_missing           0.000000\n",
            "32                 bin__dropoff_missing           0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "The model is generalising well, not overfitting or underfitting, and is accomplishing it's goal well. The top feature is distance followed manhatten distance which makes sense."
      ],
      "metadata": {
        "id": "LZwz3jyiCLB4"
      }
    }
  ]
}