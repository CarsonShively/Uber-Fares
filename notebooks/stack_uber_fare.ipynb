{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stack\n",
        "1. LightGBM\n",
        "3. XGBoost\n",
        "4. meta model - Ridge"
      ],
      "metadata": {
        "id": "XUzwWmU3HS6s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IsSR1IeOHMww"
      },
      "outputs": [],
      "source": [
        "''' !pip install -q gdown\n",
        "!pip install -q category_encoders\n",
        "!pip install -q optuna '''\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import Ridge\n",
        "import shap\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMRegressor\n",
        "import category_encoders as ce\n",
        "from category_encoders import TargetEncoder\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "uhJV8lLz_Bs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"uber.csv\", quiet=False)\n",
        "df = pd.read_csv(\"uber.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1N4jUZ-jHgc0",
        "outputId": "10375e01-d29c-4221-be87-98d277902d5b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nvFRd8uiUV8OfoihMOXZ0Emle1ksxwW1\n",
            "To: /content/uber.csv\n",
            "100%|██████████| 23.5M/23.5M [00:00<00:00, 176MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                            key  fare_amount  \\\n",
              "0    24238194    2015-05-07 19:52:06.0000003          7.5   \n",
              "1    27835199    2009-07-17 20:04:56.0000002          7.7   \n",
              "2    44984355   2009-08-24 21:45:00.00000061         12.9   \n",
              "3    25894730    2009-06-26 08:22:21.0000001          5.3   \n",
              "4    17610152  2014-08-28 17:47:00.000000188         16.0   \n",
              "\n",
              "           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
              "0  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
              "1  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
              "2  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
              "3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
              "4  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
              "\n",
              "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
              "0         -73.999512         40.723217                1  \n",
              "1         -73.994710         40.750325                1  \n",
              "2         -73.962565         40.772647                1  \n",
              "3         -73.965316         40.803349                3  \n",
              "4         -73.973082         40.761247                5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-210aca0d-2bb0-47ea-bb48-1837e2266ab1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24238194</td>\n",
              "      <td>2015-05-07 19:52:06.0000003</td>\n",
              "      <td>7.5</td>\n",
              "      <td>2015-05-07 19:52:06 UTC</td>\n",
              "      <td>-73.999817</td>\n",
              "      <td>40.738354</td>\n",
              "      <td>-73.999512</td>\n",
              "      <td>40.723217</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27835199</td>\n",
              "      <td>2009-07-17 20:04:56.0000002</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2009-07-17 20:04:56 UTC</td>\n",
              "      <td>-73.994355</td>\n",
              "      <td>40.728225</td>\n",
              "      <td>-73.994710</td>\n",
              "      <td>40.750325</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44984355</td>\n",
              "      <td>2009-08-24 21:45:00.00000061</td>\n",
              "      <td>12.9</td>\n",
              "      <td>2009-08-24 21:45:00 UTC</td>\n",
              "      <td>-74.005043</td>\n",
              "      <td>40.740770</td>\n",
              "      <td>-73.962565</td>\n",
              "      <td>40.772647</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25894730</td>\n",
              "      <td>2009-06-26 08:22:21.0000001</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2009-06-26 08:22:21 UTC</td>\n",
              "      <td>-73.976124</td>\n",
              "      <td>40.790844</td>\n",
              "      <td>-73.965316</td>\n",
              "      <td>40.803349</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17610152</td>\n",
              "      <td>2014-08-28 17:47:00.000000188</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2014-08-28 17:47:00 UTC</td>\n",
              "      <td>-73.925023</td>\n",
              "      <td>40.744085</td>\n",
              "      <td>-73.973082</td>\n",
              "      <td>40.761247</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-210aca0d-2bb0-47ea-bb48-1837e2266ab1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-210aca0d-2bb0-47ea-bb48-1837e2266ab1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-210aca0d-2bb0-47ea-bb48-1837e2266ab1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2fc7389b-bedc-47e3-9121-a63152e0604d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2fc7389b-bedc-47e3-9121-a63152e0604d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2fc7389b-bedc-47e3-9121-a63152e0604d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up\n",
        "1. Log transform to habdle skew in the target.\n",
        "2. Drop rows with nans in features without a meaningful imputation value.\n",
        "3. Establish hold out set."
      ],
      "metadata": {
        "id": "pGcQi_t6bvU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df['log_fare_amount'] = np.log1p(df['fare_amount'])\n",
        "\n",
        "df = df.dropna(subset=[\n",
        "    'pickup_latitude',\n",
        "    'pickup_longitude',\n",
        "    'dropoff_latitude',\n",
        "    'dropoff_longitude',\n",
        "    'pickup_datetime',\n",
        "    'log_fare_amount'\n",
        "])\n",
        "\n",
        "X = df.drop(columns=['fare_amount', 'log_fare_amount', 'key', 'Unnamed: 0'])\n",
        "y = df['log_fare_amount']\n",
        "\n",
        "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jDaf15hFHiVV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction\n",
        "### Datetime features extracted (originals dropped)\n",
        "1. hour\n",
        "2. weekday\n",
        "3. month\n",
        "4. is weekend\n",
        "5. is rush hour\n",
        "6. missing datatime flag\n",
        "\n",
        "If datetime extractor is unable to extract useable datatime, filled with place holder, to prevent crash.\n",
        "\n",
        "### Coordinate features extracted (originals dropped)\n",
        "1. haversine distance\n",
        "2. manhatten distance\n",
        "3. barring\n",
        "4. pickup cluster\n",
        "5. dropoff cluster\n",
        "6. pickup grid\n",
        "7. dropoff grid\n",
        "8. pickup coordinate missing flag\n",
        "9. dropoff coordinate missing flag\n",
        "\n",
        "If coordinate extractor is unable to extract useable coordinates, filled with place holder, to prevent crash."
      ],
      "metadata": {
        "id": "nQqF1j4mbxTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, datetime_column='pickup_datetime', add_missing_flag=True):\n",
        "        self.datetime_column = datetime_column\n",
        "        self.add_missing_flag = add_missing_flag\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "        self.placeholder = pd.Timestamp(\"1900-01-01 00:00:00\")\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        X[self.datetime_column] = pd.to_datetime(X[self.datetime_column], errors='coerce')\n",
        "\n",
        "        if self.add_missing_flag:\n",
        "            X[f'{self.datetime_column}_missing'] = X[self.datetime_column].isna()\n",
        "\n",
        "        X[self.datetime_column] = X[self.datetime_column].fillna(self.placeholder)\n",
        "\n",
        "        X['hour'] = X[self.datetime_column].dt.hour\n",
        "        X['weekday'] = X[self.datetime_column].dt.weekday\n",
        "        X['month'] = X[self.datetime_column].dt.month\n",
        "        X['is_weekend'] = X['weekday'] >= 5\n",
        "        X['is_rush_hour'] = X['hour'].isin([7, 8, 9, 16, 17, 18, 19])\n",
        "\n",
        "        X.drop(columns=[self.datetime_column], inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CoordinateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_clusters=20, placeholder=-999.0):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.placeholder = placeholder\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "        self.kmeans_pickup = None\n",
        "        self.kmeans_dropoff = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        pickup_coords  = X[[\"pickup_latitude\", \"pickup_longitude\"]].astype(float)\n",
        "        dropoff_coords = X[[\"dropoff_latitude\", \"dropoff_longitude\"]].astype(float)\n",
        "\n",
        "        self.kmeans_pickup  = KMeans(n_clusters=self.n_clusters, random_state=42).fit(pickup_coords)\n",
        "        self.kmeans_dropoff = KMeans(n_clusters=self.n_clusters, random_state=42).fit(dropoff_coords)\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "\n",
        "        geo_cols = [\n",
        "            \"pickup_latitude\", \"pickup_longitude\",\n",
        "            \"dropoff_latitude\", \"dropoff_longitude\",\n",
        "        ]\n",
        "        for col in geo_cols:\n",
        "            X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
        "\n",
        "        X[\"pickup_missing\"]  = X[[\"pickup_latitude\", \"pickup_longitude\"]].isna().any(axis=1)\n",
        "        X[\"dropoff_missing\"] = X[[\"dropoff_latitude\", \"dropoff_longitude\"]].isna().any(axis=1)\n",
        "\n",
        "        for col in geo_cols:\n",
        "            X[col] = X[col].fillna(self.placeholder)\n",
        "\n",
        "        X[\"pickup_latitude\"]   = X[\"pickup_latitude\"].clip(40.5, 41.0)\n",
        "        X[\"pickup_longitude\"]  = X[\"pickup_longitude\"].clip(-74.3, -73.6)\n",
        "        X[\"dropoff_latitude\"]  = X[\"dropoff_latitude\"].clip(40.5, 41.0)\n",
        "        X[\"dropoff_longitude\"] = X[\"dropoff_longitude\"].clip(-74.3, -73.6)\n",
        "\n",
        "        def haversine(lat1, lon1, lat2, lon2):\n",
        "            R = 6371.0\n",
        "            lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "            dlat = lat2 - lat1\n",
        "            dlon = lon2 - lon1\n",
        "            a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
        "            return R * 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "        def manhattan(lat1, lon1, lat2, lon2):\n",
        "            return haversine(lat1, lon1, lat2, lon1) + haversine(lat2, lon1, lat2, lon2)\n",
        "\n",
        "        def bearing(lat1, lon1, lat2, lon2):\n",
        "            dlon = np.radians(lon2 - lon1)\n",
        "            lat1, lat2 = np.radians(lat1), np.radians(lat2)\n",
        "            x = np.sin(dlon) * np.cos(lat2)\n",
        "            y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(dlon)\n",
        "            return (np.degrees(np.arctan2(x, y)) + 360) % 360\n",
        "\n",
        "        X[\"distance_km\"] = haversine(\n",
        "            X[\"pickup_latitude\"], X[\"pickup_longitude\"],\n",
        "            X[\"dropoff_latitude\"], X[\"dropoff_longitude\"]\n",
        "        )\n",
        "\n",
        "        X[\"manhattan_km\"] = manhattan(\n",
        "            X[\"pickup_latitude\"], X[\"pickup_longitude\"],\n",
        "            X[\"dropoff_latitude\"], X[\"dropoff_longitude\"]\n",
        "        )\n",
        "\n",
        "        X[\"bearing\"] = bearing(\n",
        "            X[\"pickup_latitude\"], X[\"pickup_longitude\"],\n",
        "            X[\"dropoff_latitude\"], X[\"dropoff_longitude\"]\n",
        "        )\n",
        "\n",
        "        p_lat_g = X[\"pickup_latitude\"].round(3)\n",
        "        p_lon_g = X[\"pickup_longitude\"].round(3)\n",
        "        d_lat_g = X[\"dropoff_latitude\"].round(3)\n",
        "        d_lon_g = X[\"dropoff_longitude\"].round(3)\n",
        "\n",
        "        X[\"grid_distance_km\"] = manhattan(p_lat_g, p_lon_g, d_lat_g, d_lon_g)\n",
        "\n",
        "        X[\"pickup_cluster\"]  = self.kmeans_pickup.predict(X[[\"pickup_latitude\", \"pickup_longitude\"]])\n",
        "        X[\"dropoff_cluster\"] = self.kmeans_dropoff.predict(X[[\"dropoff_latitude\", \"dropoff_longitude\"]])\n",
        "\n",
        "        X[\"pickup_grid\"] = p_lat_g.astype(str) + \"_\" + p_lon_g.astype(str)\n",
        "        X[\"dropoff_grid\"] = d_lat_g.astype(str) + \"_\" + d_lon_g.astype(str)\n",
        "\n",
        "        X.drop(columns=geo_cols, inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y6L8GKHNJy1n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "UoPwhyoKonZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DurationEstimator(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, rush_speed_kmh: float = 20.0, normal_speed_kmh: float = 30.0):\n",
        "        self.rush_speed_kmh = rush_speed_kmh\n",
        "        self.normal_speed_kmh = normal_speed_kmh\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self._fitted_ = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        from sklearn.utils.validation import check_is_fitted\n",
        "        check_is_fitted(self, \"_fitted_\")\n",
        "\n",
        "        X = X.copy()\n",
        "        distance = X[\"manhattan_km\"] if \"manhattan_km\" in X else X[\"distance_km\"]\n",
        "        speed_kmh = (\n",
        "            np.where(X[\"is_rush_hour\"], self.rush_speed_kmh, self.normal_speed_kmh)\n",
        "            if \"is_rush_hour\" in X\n",
        "            else self.normal_speed_kmh\n",
        "        )\n",
        "        X[\"estimated_duration_min\"] = (distance / speed_kmh) * 60\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "class PickupClusterDensity(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        cluster_col: str = \"pickup_cluster\",\n",
        "        output_name: str = \"pickup_cluster_density\",\n",
        "    ):\n",
        "        self.cluster_col = cluster_col\n",
        "        self.output_name = output_name\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X_df = pd.DataFrame(X)\n",
        "        if self.cluster_col not in X_df.columns:\n",
        "            raise ValueError(f\"Column {self.cluster_col!r} not found in input.\")\n",
        "\n",
        "        counts = X_df[self.cluster_col].value_counts(dropna=False).astype(float)\n",
        "        total = float(len(X_df))\n",
        "        self._density_ = (counts / total).to_dict()\n",
        "        self._global_density_ = 1.0 / total\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, [\"_density_\"])\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "\n",
        "        X_out[self.output_name] = (\n",
        "            X_out[self.cluster_col]\n",
        "            .map(self._density_)\n",
        "            .fillna(self._global_density_)\n",
        "        )\n",
        "\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class GridAvgFareOOF(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        grid_col: str = \"pickup_grid\",\n",
        "        output_name: str = \"grid_avg_fare\",\n",
        "        n_splits: int = 5,\n",
        "        random_state: int = 42,\n",
        "        handle_unseen: str = \"global_mean\",\n",
        "    ):\n",
        "        self.grid_col = grid_col\n",
        "        self.output_name = output_name\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "        self.handle_unseen = handle_unseen\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_df = pd.DataFrame(X).reset_index(drop=True)\n",
        "        if self.grid_col not in X_df.columns:\n",
        "            raise ValueError(f\"Column {self.grid_col!r} not found in input.\")\n",
        "\n",
        "        y = pd.Series(y).reset_index(drop=True)\n",
        "        kf = KFold(\n",
        "            n_splits=self.n_splits,\n",
        "            shuffle=True,\n",
        "            random_state=self.random_state,\n",
        "        )\n",
        "\n",
        "        oof_vals = pd.Series(np.nan, index=X_df.index, dtype=float)\n",
        "\n",
        "        for train_idx, val_idx in kf.split(X_df):\n",
        "            means = (\n",
        "                pd.DataFrame(\n",
        "                    {self.grid_col: X_df.loc[train_idx, self.grid_col], \"y\": y[train_idx]}\n",
        "                )\n",
        "                .groupby(self.grid_col)[\"y\"]\n",
        "                .mean()\n",
        "            )\n",
        "            oof_vals.loc[val_idx] = (\n",
        "                X_df.loc[val_idx, self.grid_col]\n",
        "                .map(means)\n",
        "                .fillna(y[train_idx].mean())\n",
        "            )\n",
        "\n",
        "        self._oof_values_ = oof_vals\n",
        "        self._grid_means_ = (\n",
        "            pd.DataFrame({self.grid_col: X_df[self.grid_col], \"y\": y})\n",
        "            .groupby(self.grid_col)[\"y\"]\n",
        "            .mean()\n",
        "            .to_dict()\n",
        "        )\n",
        "        self._global_mean_ = float(y.mean())\n",
        "        self._return_oof_ = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, [\"_grid_means_\"])\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "\n",
        "        if self._return_oof_ and len(X_out) == len(self._oof_values_):\n",
        "            X_out[self.output_name] = self._oof_values_.values\n",
        "            self._return_oof_ = False\n",
        "            return X_out\n",
        "\n",
        "        mapped = X_out[self.grid_col].map(self._grid_means_)\n",
        "        if self.handle_unseen == \"global_mean\":\n",
        "            mapped = mapped.fillna(self._global_mean_)\n",
        "        X_out[self.output_name] = mapped.astype(float)\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class PickupDropFreq(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pickup_col: str = \"pickup_cluster\",\n",
        "        dropoff_col: str = \"dropoff_cluster\",\n",
        "        output_name: str = \"pickup_drop_freq\",\n",
        "        handle_unseen: str = \"global_mean\",\n",
        "    ):\n",
        "        self.pickup_col = pickup_col\n",
        "        self.dropoff_col = dropoff_col\n",
        "        self.output_name = output_name\n",
        "        self.handle_unseen = handle_unseen\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "    def fit(self, X, y=None):\n",
        "        X_df = pd.DataFrame(X)\n",
        "\n",
        "        missing_cols = [c for c in [self.pickup_col, self.dropoff_col] if c not in X_df]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Input is missing columns: {missing_cols}\")\n",
        "\n",
        "\n",
        "        pair_counts = (\n",
        "            X_df.groupby([self.pickup_col, self.dropoff_col], dropna=False)\n",
        "                .size()\n",
        "                .astype(float)\n",
        "        )\n",
        "        total = float(len(X_df))\n",
        "        self._freq_ = (pair_counts / total).to_dict()\n",
        "        self._global_mean_ = 1.0 / total\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, [\"_freq_\"])\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "\n",
        "        pairs = list(zip(X_out[self.pickup_col], X_out[self.dropoff_col]))\n",
        "        mapped = pd.Series(pairs).map(self._freq_)\n",
        "\n",
        "        if self.handle_unseen == \"global_mean\":\n",
        "            mapped = mapped.fillna(self._global_mean_)\n",
        "\n",
        "        X_out[self.output_name] = mapped.astype(float)\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class ColumnPairConcat(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, col_a, col_b, output_col, as_string: bool = True):\n",
        "        self.col_a = col_a\n",
        "        self.col_b = col_b\n",
        "        self.output_col = output_col\n",
        "        self.as_string = as_string\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "        if self.col_a not in X_out or self.col_b not in X_out:\n",
        "            missing = [c for c in [self.col_a, self.col_b] if c not in X_out]\n",
        "            raise ValueError(f\"Missing columns: {missing}\")\n",
        "\n",
        "        combo = X_out[self.col_a].astype(str) + \"_\" + X_out[self.col_b].astype(str)\n",
        "        if self.as_string:\n",
        "            X_out[self.output_col] = combo\n",
        "        else:\n",
        "\n",
        "            X_out[self.output_col] = combo.apply(lambda s: hash(s) & 0x7FFFFFFF)\n",
        "\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class SameClusterFlag(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pickup_col: str = \"pickup_cluster\",\n",
        "        dropoff_col: str = \"dropoff_cluster\",\n",
        "        output_col: str = \"same_cluster\",\n",
        "    ):\n",
        "        self.pickup_col = pickup_col\n",
        "        self.dropoff_col = dropoff_col\n",
        "        self.output_col = output_col\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "\n",
        "        missing = [c for c in [self.pickup_col, self.dropoff_col] if c not in X_out]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Input is missing columns: {missing}\")\n",
        "\n",
        "        X_out[self.output_col] = (\n",
        "            X_out[self.pickup_col] == X_out[self.dropoff_col]\n",
        "        )\n",
        "\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class DistanceComparisons(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        distance_col: str = \"distance_km\",\n",
        "        manhattan_col: str = \"manhattan_km\",\n",
        "        ratio_name: str = \"distance_over_manhattan\",\n",
        "        diff_name: str = \"manhattan_minus_distance\",\n",
        "        eps: float = 1e-6,\n",
        "    ):\n",
        "        self.distance_col = distance_col\n",
        "        self.manhattan_col = manhattan_col\n",
        "        self.ratio_name = ratio_name\n",
        "        self.diff_name = diff_name\n",
        "        self.eps = eps\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "\n",
        "        missing = [\n",
        "            c\n",
        "            for c in [self.distance_col, self.manhattan_col]\n",
        "            if c not in X_out.columns\n",
        "        ]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Input is missing columns: {missing}\")\n",
        "\n",
        "        d  = X_out[self.distance_col].astype(float)\n",
        "        dm = X_out[self.manhattan_col].astype(float)\n",
        "\n",
        "        X_out[self.ratio_name] = d / (dm + self.eps)\n",
        "\n",
        "        X_out[self.diff_name] = dm - d\n",
        "\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class TimeOfDayFlags(BaseEstimator, TransformerMixin):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hour_col: str = \"hour\",\n",
        "        work_hours: tuple = (9, 17),\n",
        "        morning_range: tuple = (5, 11),\n",
        "        afternoon_range: tuple = (12, 16),\n",
        "        night_range: tuple = (21, 4),\n",
        "        output_prefix: str = \"\",\n",
        "    ):\n",
        "        self.hour_col = hour_col\n",
        "        self.work_hours = work_hours\n",
        "        self.morning_range = morning_range\n",
        "        self.afternoon_range = afternoon_range\n",
        "        self.night_range = night_range\n",
        "        self.output_prefix = output_prefix\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def _in_range(self, h, rng):\n",
        "\n",
        "        start, end = rng\n",
        "        if start <= end:\n",
        "            return (h >= start) & (h <= end)\n",
        "        else:\n",
        "            return (h >= start) | (h <= end)\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "\n",
        "        if self.hour_col not in X_out.columns:\n",
        "            raise ValueError(f\"Column '{self.hour_col}' not found in input.\")\n",
        "\n",
        "        h = X_out[self.hour_col].astype(int)\n",
        "\n",
        "        X_out[f\"{self.output_prefix}is_work_hour\"] = self._in_range(h, self.work_hours)\n",
        "        X_out[f\"{self.output_prefix}is_morning\"]   = self._in_range(h, self.morning_range)\n",
        "        X_out[f\"{self.output_prefix}is_afternoon\"] = self._in_range(h, self.afternoon_range)\n",
        "        X_out[f\"{self.output_prefix}is_night\"]     = self._in_range(h, self.night_range)\n",
        "\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class GridDistanceInteractions(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dist_col: str = \"distance_km\",\n",
        "        grid_dist_col: str = \"grid_distance_km\",\n",
        "        bearing_col: str = \"bearing\",\n",
        "        prefix: str = \"\",\n",
        "    ):\n",
        "        self.dist_col = dist_col\n",
        "        self.grid_dist_col = grid_dist_col\n",
        "        self.bearing_col = bearing_col\n",
        "        self.prefix = prefix\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self._fitted_ = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, \"_fitted_\")\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "\n",
        "        required = [self.dist_col, self.grid_dist_col, self.bearing_col]\n",
        "        missing = [c for c in required if c not in X_out.columns]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Input is missing columns: {missing}\")\n",
        "\n",
        "        d  = X_out[self.dist_col].astype(float)\n",
        "        gd = X_out[self.grid_dist_col].astype(float)\n",
        "        b  = X_out[self.bearing_col].astype(float)\n",
        "\n",
        "        X_out[f\"{self.prefix}dist_times_grid_dist\"]   = d * gd\n",
        "        X_out[f\"{self.prefix}bearing_times_dist\"]     = b * d\n",
        "        X_out[f\"{self.prefix}bearing_times_grid_dist\"] = b * gd\n",
        "\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self"
      ],
      "metadata": {
        "id": "RT53XqJToo8x"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering pipeline"
      ],
      "metadata": {
        "id": "-tlxQaLjJbLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fe_pipeline = Pipeline([\n",
        "    (\"duration_est\",          DurationEstimator()),\n",
        "    (\"pickup_cluster_dens\",   PickupClusterDensity()),\n",
        "    (\"pickup_drop_freq\",      PickupDropFreq()),\n",
        "    (\"grid_avg_fare\",         GridAvgFareOOF()), #double check leakage\n",
        "    (\"same_cluster_flag\",     SameClusterFlag()),\n",
        "    (\"tod_flags\",             TimeOfDayFlags()),\n",
        "    (\"dist_comparisons\",      DistanceComparisons()),\n",
        "    (\"cluster_interaction\",   ColumnPairConcat(\"pickup_cluster\",\n",
        "                                               \"dropoff_cluster\",\n",
        "                                               \"cluster_interaction\",\n",
        "                                               as_string=True)),\n",
        "    (\"grid_interaction\",      ColumnPairConcat(\"pickup_grid\",\n",
        "                                               \"dropoff_grid\",\n",
        "                                               \"grid_interaction\",\n",
        "                                               as_string=True)),\n",
        "    (\"grid_interactions\", GridDistanceInteractions(prefix=\"int_\")),\n",
        "])"
      ],
      "metadata": {
        "id": "CvZfjF7CJdEq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom classes\n",
        "1. To float\n",
        "2. Clip to valid range\n",
        "3. Cyclic transforer\n",
        "4. Target encode wrapper"
      ],
      "metadata": {
        "id": "0i7TOJQQb0KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToFloat64(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce').astype('float64')\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class ClipToValidRange(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, valid_min=1, valid_max=6):\n",
        "        self.valid_min = valid_min\n",
        "        self.valid_max = valid_max\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        for col in X.columns:\n",
        "            mask = X[col].between(self.valid_min, self.valid_max)\n",
        "            X[col] = X[col].where(mask, np.nan)\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CyclicFeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"default\"}\n",
        "\n",
        "        self.hour_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 24),\n",
        "            np.cos(2 * np.pi * X / 24)\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.bearing_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(np.radians(X)),\n",
        "            np.cos(np.radians(X))\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.weekday_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 7),\n",
        "            np.cos(2 * np.pi * X / 7)\n",
        "        ]), validate=False)\n",
        "\n",
        "        self.month_transformer = FunctionTransformer(lambda X: np.column_stack([\n",
        "            np.sin(2 * np.pi * X / 12),\n",
        "            np.cos(2 * np.pi * X / 12)\n",
        "        ]), validate=False)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = X.copy()\n",
        "        result = pd.DataFrame(index=X.index)\n",
        "\n",
        "        if 'hour' in X.columns:\n",
        "            hour_transformed = self.hour_transformer.transform(X[['hour']])\n",
        "            result[['hour_sin', 'hour_cos']] = pd.DataFrame(hour_transformed, index=X.index)\n",
        "\n",
        "        if 'bearing' in X.columns:\n",
        "            bearing_transformed = self.bearing_transformer.transform(X[['bearing']])\n",
        "            result[['bearing_sin', 'bearing_cos']] = pd.DataFrame(bearing_transformed, index=X.index)\n",
        "\n",
        "        if 'weekday' in X.columns:\n",
        "            weekday_transformed = self.weekday_transformer.transform(X[['weekday']])\n",
        "            result[['weekday_sin', 'weekday_cos']] = pd.DataFrame(weekday_transformed, index=X.index)\n",
        "\n",
        "        if 'month' in X.columns:\n",
        "            month_transformed = self.month_transformer.transform(X[['month']])\n",
        "            result[['month_sin', 'month_cos']] = pd.DataFrame(month_transformed, index=X.index)\n",
        "\n",
        "        for col in ['hour', 'bearing', 'weekday', 'month']:\n",
        "            if col in X.columns:\n",
        "                X.drop(columns=[col], inplace=True)\n",
        "\n",
        "        X = pd.concat([X, result], axis=1)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self\n",
        "\n",
        "class InfToNanConverter(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, columns=None):\n",
        "        self.columns = columns\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if isinstance(self.columns, list) and len(self.columns) and isinstance(X, pd.DataFrame):\n",
        "            self._col_idx_ = [X.columns.get_loc(c) if isinstance(c, str) else c\n",
        "                              for c in self.columns]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, [])\n",
        "        X_out = pd.DataFrame(X).copy()\n",
        "\n",
        "        if self.columns is None:\n",
        "            cols = X_out.columns\n",
        "        else:\n",
        "            cols = self.columns if not hasattr(self, \"_col_idx_\") else self._col_idx_\n",
        "\n",
        "        X_out[cols] = X_out[cols].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self\n",
        "\n",
        "class CategoryCaster(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self._output_config = {\"transform\": \"pandas\"}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_out = pd.DataFrame(X).copy().astype(\"category\")\n",
        "        return X_out\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        self._output_config[\"transform\"] = transform\n",
        "        return self"
      ],
      "metadata": {
        "id": "IkVS0VkYJ-WD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passenger feature\n",
        "1. Coerce to float for uniformed nans.\n",
        "2. Clip range to 1-6 people.\n",
        "3. Impute with the mode."
      ],
      "metadata": {
        "id": "AcEnKikCb2Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_pipeline = Pipeline([\n",
        "    ('coerce', ToFloat64()),\n",
        "    ('clip', ClipToValidRange()),\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "])"
      ],
      "metadata": {
        "id": "4pwGHlr-KAGS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary features\n",
        "1. Coerce to float for numeric binarys, 0 1."
      ],
      "metadata": {
        "id": "_ZcyoG75b30P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_pipeline = Pipeline([\n",
        "    ('coerce', ToFloat64()),\n",
        "])"
      ],
      "metadata": {
        "id": "NDUm-VIATZGT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cyclic features\n",
        "1. Convert to sinusoidal compenents."
      ],
      "metadata": {
        "id": "1-_RT9T4b70L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cyclic_pipeline = Pipeline([\n",
        "    ('cyclic', CyclicFeatureTransformer()),\n",
        "])"
      ],
      "metadata": {
        "id": "dkHafC2qKDlS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ordinal features\n",
        "1. Pairs well with tree based models used in this stack."
      ],
      "metadata": {
        "id": "nCtzoo6fb9sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_pipeline = Pipeline([\n",
        "    (\"cast_cat\", CategoryCaster()),\n",
        "])"
      ],
      "metadata": {
        "id": "41SM-S7uKFBW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ratio pipeline"
      ],
      "metadata": {
        "id": "SmUJRz4QEnAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratio_pipeline = Pipeline([\n",
        "    ('inf', InfToNanConverter()),\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "])"
      ],
      "metadata": {
        "id": "Oagtr94uEodO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop low impact features"
      ],
      "metadata": {
        "id": "aj81c-m5cFRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DropFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.features_to_drop = [\n",
        "\n",
        "]\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        drop_cols = [col for col in self.features_to_drop if col in X.columns]\n",
        "        return X.drop(columns=drop_cols)\n",
        "\n",
        "    def set_output(self, *, transform=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "Y3wOVjihoECG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "VKXDgPObcNu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_features = ['passenger_count']\n",
        "binary_features = ['is_weekend', 'is_rush_hour', 'pickup_missing', 'dropoff_missing', 'pickup_datetime_missing', 'same_cluster', \"is_work_hour\", \"is_morning\", \"is_afternoon\", \"is_night\",]\n",
        "cyclic_features = ['hour', 'bearing', 'weekday', 'month']\n",
        "categorical_features = ['pickup_cluster', 'dropoff_cluster', 'pickup_grid', 'dropoff_grid', 'cluster_interaction', 'grid_interaction']\n",
        "ratio_features = [\n",
        "    \"distance_over_manhattan\", \"distance_ratio\", \"grid_to_manhattan_ratio\", \"grid_to_direct_ratio\",\n",
        "]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('pass', passenger_pipeline, passenger_features),\n",
        "    ('cyclic', cyclic_pipeline, cyclic_features),\n",
        "    ('bin', binary_pipeline, binary_features),\n",
        "    ('ord', categorical_pipeline, categorical_features),\n",
        "    ('rat', ratio_pipeline, ratio_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "base_learners = [\n",
        "    ('lgbm', LGBMRegressor(random_state=42, n_jobs=-1)),\n",
        "    ('xgb', xgb.XGBRegressor(\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        tree_method='hist',\n",
        "        enable_categorical=True\n",
        "    ))\n",
        "]\n",
        "\n",
        "meta_model = Ridge(random_state=42)\n",
        "\n",
        "stacked_model = StackingRegressor(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_model,\n",
        "    passthrough=False,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('datetime_features',  DatetimeFeatureExtractor(datetime_column='pickup_datetime')),\n",
        "    ('coordinate_features', CoordinateFeatureExtractor(n_clusters=20)),\n",
        "    ('feature_engineering', fe_pipeline),\n",
        "    ('preprocessing',       preprocessor),\n",
        "    ('model',               stacked_model)\n",
        "])\n",
        "\n",
        "full_pipeline.set_output(transform='pandas')\n",
        "\n",
        "_ = full_pipeline"
      ],
      "metadata": {
        "id": "0kZ_58p_Ml0F"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics"
      ],
      "metadata": {
        "id": "-BmfZFZroL-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_subtrain, X_val, y_subtrain, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "full_pipeline.fit(X_subtrain, y_subtrain)\n",
        "y_val_pred_log = full_pipeline.predict(X_val)\n",
        "\n",
        "y_val_true = np.expm1(y_val)\n",
        "y_val_pred = np.expm1(y_val_pred_log)\n",
        "\n",
        "val_rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred))\n",
        "val_mse = mean_squared_error(y_val_true, y_val_pred)\n",
        "val_mae = mean_absolute_error(y_val_true, y_val_pred)\n",
        "val_r2 = r2_score(y_val_true, y_val_pred)\n",
        "\n",
        "print(\"Validation Set Metrics (Un-logged, in dollars):\")\n",
        "print(f\"RMSE: ${val_rmse:.4f}\")\n",
        "print(f\"MSE:  ${val_mse:.4f}\")\n",
        "print(f\"MAE:  ${val_mae:.4f}\")\n",
        "print(f\"R²:   {val_r2:.4f}\")\n",
        "\n",
        "full_pipeline.fit(X_train, y_train)\n",
        "y_holdout_pred_log = full_pipeline.predict(X_holdout)\n",
        "\n",
        "y_holdout_true = np.expm1(y_holdout)\n",
        "y_holdout_pred = np.expm1(y_holdout_pred_log)\n",
        "\n",
        "holdout_rmse = np.sqrt(mean_squared_error(y_holdout_true, y_holdout_pred))\n",
        "holdout_mse = mean_squared_error(y_holdout_true, y_holdout_pred)\n",
        "holdout_mae = mean_absolute_error(y_holdout_true, y_holdout_pred)\n",
        "holdout_r2 = r2_score(y_holdout_true, y_holdout_pred)\n",
        "\n",
        "print(\"\\nHold-Out Set Metrics (Un-logged, in dollars):\")\n",
        "print(f\"RMSE: ${holdout_rmse:.4f}\")\n",
        "print(f\"MSE:  ${holdout_mse:.4f}\")\n",
        "print(f\"MAE:  ${holdout_mae:.4f}\")\n",
        "print(f\"R²:   {holdout_r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "WFP06gEgZUCo",
        "outputId": "07cd57b4-5b55-4eed-c3ea-c2b03bff95db"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: '40.748_-73.977'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3591622484.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_subtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_val_pred_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    728\u001b[0m             )\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 return last_step.fit_transform(\n\u001b[0m\u001b[1;32m    731\u001b[0m                     \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlast_step_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2976886548.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0md\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mX_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mb\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mX_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbearing_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickup_grid_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mdg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_grid_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6641\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6642\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6643\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6644\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_astype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '40.748_-73.977'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shap feature analysis"
      ],
      "metadata": {
        "id": "F2-uP8f4oAbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sampled = X_holdout.sample(n=1000, random_state=42)\n",
        "\n",
        "X_sampled_transformed = full_pipeline[:-1].transform(X_sampled)\n",
        "\n",
        "model = full_pipeline.named_steps['model']\n",
        "\n",
        "explainer = shap.Explainer(model.predict, X_sampled_transformed)\n",
        "shap_values = explainer(X_sampled_transformed)\n",
        "\n",
        "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': X_sampled_transformed.columns,\n",
        "    'Mean |SHAP Value|': mean_abs_shap\n",
        "}).sort_values(by='Mean |SHAP Value|', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nSHAP Feature Importances (All Features):\")\n",
        "print(shap_importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hr0pUAR1LC-",
        "outputId": "111874f9-dd21-4301-c9ec-6502998624a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PermutationExplainer explainer: 1001it [06:35,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SHAP Feature Importances (All Features):\n",
            "                                Feature  Mean |SHAP Value|\n",
            "0                     clip__distance_km           0.327966\n",
            "1                     tar__dropoff_grid           0.063032\n",
            "2                      tar__pickup_grid           0.047075\n",
            "3          clip__cluster_bearing_offset           0.033566\n",
            "4                      cyclic__hour_cos           0.032946\n",
            "5                   cyclic__bearing_sin           0.025823\n",
            "6            clip__distance_bearing_sin           0.021834\n",
            "7                  ord__dropoff_cluster           0.019436\n",
            "8                   cyclic__bearing_cos           0.018480\n",
            "9                  clip__distance_ratio           0.016964\n",
            "10                     cyclic__hour_sin           0.015312\n",
            "11                  ord__pickup_cluster           0.012587\n",
            "12                   clip__manhattan_km           0.010888\n",
            "13                  cyclic__weekday_cos           0.010309\n",
            "14    clip__distance_times_cluster_diff           0.008271\n",
            "15                  cyclic__weekday_sin           0.008004\n",
            "16                   clip__cluster_diff           0.006535\n",
            "17                    cyclic__month_sin           0.006132\n",
            "18                    cyclic__month_cos           0.006043\n",
            "19                pass__passenger_count           0.004866\n",
            "20              clip__hour_x_is_weekend           0.004158\n",
            "21               ohe__time_of_day_night           0.003331\n",
            "22            clip__hour_x_is_rush_hour           0.001871\n",
            "23  remainder__pickup_dropoff_same_grid           0.001793\n",
            "24                    bin__is_rush_hour           0.000386\n",
            "25             ohe__time_of_day_morning           0.000252\n",
            "26           ohe__time_of_day_afternoon           0.000232\n",
            "27             ohe__time_of_day_evening           0.000186\n",
            "28                    bin__is_peak_hour           0.000007\n",
            "29                      bin__is_weekend           0.000005\n",
            "30         bin__pickup_datetime_missing           0.000000\n",
            "31                  bin__pickup_missing           0.000000\n",
            "32                 bin__dropoff_missing           0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "The model is generalising well, not overfitting or underfitting, and is accomplishing it's goal well. The top feature is distance followed manhatten distance which makes sense."
      ],
      "metadata": {
        "id": "LZwz3jyiCLB4"
      }
    }
  ]
}